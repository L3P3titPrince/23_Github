{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Unsupervised Learing: Text Clustering</center>\n",
    "\n",
    "References:\n",
    "* https://www-users.cs.umn.edu/~kumar/dmbook/ch8.pdf\n",
    "* http://infolab.stanford.edu/~ullman/mmds/ch7.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering vs. Classification\n",
    "* Clustering (Unsupervised): divide a set of objects into clusters (parts of the set) so that objects in the same cluster are similar to each other, and/or objects in different clusters are dissimilar.\n",
    "  * Representation of the objects\n",
    "  * Similarity/distance measure\n",
    "* Classifification (Supervised): group objects into predetermined categories\n",
    "  * Representation of the objects\n",
    "  * A training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size = 15>Clustering 我们不知道groudtruth label</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why clustering\n",
    "* Understand conceptually meaningful groups of objects that share common characteristics \n",
    "* Provides an abstraction from individual data objects to the clusters in which those data objects reside\n",
    "* Uses of clustering\n",
    "  * Summarization\n",
    "  * Compression\n",
    "  * Efficiently finding nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Types of Clusterings \n",
    "* Different kinds of models (https://www.geeksforgeeks.org/different-types-clustering-algorithm/):\n",
    "  - <font color=red>Centroid models (partition) =  K-Means - 由中心决定类:</font> \n",
    "     - Similarity is derived as the closeness of a data point to the centroid of clusters. \n",
    "     - Flat partition, e.g. K-Means\n",
    "     <img src='centroid.png' width=\"40%\">\n",
    "  - Connectivity models (Hierarchical algorithms) = bottom up!: \n",
    "     - Data points closer in data space exhibit more similarity to each other than the data points lying farther away.      \n",
    "     -  <font color=red>Hierarchy of clusters</font> , e.g. agglomerative clustering\n",
    "     <img src='connectivity.png' width=\"40%\">\n",
    "  - Distribution models: \n",
    "     - How probable is it that all data points in the cluster belong to the same distribution, concept, or topic\n",
    "     - e.g.<font color=red> Latent Semantics Analysis = PCA (在文字处理中, 就是叫LSA)</font>, Latent Dirichlet Allocation (LDA)\n",
    "     <img src='distribution.png' width=\"40%\">\n",
    "  - <font color = read> Density models = outlier detection</font>: clusters correspond to areas of varied density of data points in the data space - 一般他们在sparse的地方, 所以可以称之为outlier\n",
    "     - e.g. DBSCAN\n",
    "     <img src='density.png' width=\"40%\">\n",
    "* Exclusive vs. Overlapping\n",
    "  - Exclusive: each object is assigned to a single cluster, e.g. K-Means\n",
    "  - Overlapping (non-exclusive): an object can simultaneously belong to more than one cluster, e.g. LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation of Clustering: What is a good clustering\n",
    "### 4.1 External Evaluation: \n",
    "* External evaluation measures the degree to which predicted clustering labels correspond to actual class labels  \n",
    "* **Precision** and **Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Internal Evaluation \n",
    "<img src='cohension_separation.png' width=\"60%\">\n",
    "* **Cohension (Intra-cluster similarity)**: how \"cohesive\" a cluster is, i.e. the average similarity of objects in the same cluster. \n",
    "   - e.g. cluster radius: $\\max{d(x, μ_A)}$ where $μ_A$ is the arithmetic mean of cluster A and $x$ is a point in A\n",
    "   - e.g. cluster diameter: $\\max{d(x, y)}$ where $x,y$ are two points in cluster A\n",
    "\n",
    "* **Separation (Inter-cluster dissimilarity)**: how \"separate\" a cluster from another, i.e. the average similarity of all samples in cluster $A$ to all the samples in cluster $B$.\n",
    "   - e.g. Separation can be calculated as average distance: $\\frac{1}{|A|*|B|}\\sum_{x \\in A}{\\sum_{y \\in B}{d(x, y)}}$ \n",
    "* Metrics with combined cohension and separation (http://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation)\n",
    "   - Silhouette Coefficient: $s=\\frac{b-a}{\\max(a,b)}$, where $a$: the mean distance between a sample and all other points in the same cluster, and $b$: the mean distance between a sample and all other points in the next nearest cluster. $s \\in [-1, 1]$.\n",
    "   - Calinski-Harabaz Index: $s=\\frac{b}{a}$ where $a$ is mean within\\-cluster separation, and $b$ is the mean between\\-cluster separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Means\n",
    "### 5.1. Algorithm outline: Cluster objects into K clusters\n",
    "<img style=\"float: left;\" src='Kmean1.png'  width='20%'/><img  src='Kmean2.png' width='20%'/>\n",
    "- Algorithm: \n",
    "    1. Select K points as initial centroids \n",
    "    2. Repeat until centroids do not change:\n",
    "        1. Form K clusters by assigning each point to its closest centroid by distance.\n",
    "        2. Recompute the centroid of each cluster as the arithmetic mean of samples within the cluster. \n",
    "- A few observations of K-means:\n",
    "  - Initial centroids have an impact on clustering. Usually, several rounds of clustering with random initial centroids are performed, and the most commonly occurring output centroids are chosen.\n",
    "  - Centroids and distance measure are crtical in the algorithm\n",
    "     - **Euclidean distance**: \n",
    "       - The best centroid for minimizing the average distance from all samples to the centroid is the mean of points in the cluster (https://www-users.cs.umn.edu/~kumar001/dmbook/ch8.pdf)\n",
    "       - Curse of dimensionality\n",
    "       - Sensitive to outliers\n",
    "     - **Cosine similarity**: \n",
    "       * Well-accepted similarity measure for documents\n",
    "       * It is not guaranteed that the mean of samples in a cluster is the best centroid \n",
    "       * For text clustering, the centroid does not stand for an actual document. How to interpret clusters?\n",
    "     - A modified version of Kmeans is called **K-medoids = 一个点作为中心 real**, where a representative sample is choosen as the center of a cluster, called as a medoid.  **pyclustering 中包含了这个**\n",
    "- Python packages for Kmean\n",
    "  * NLTK: can choose Euclidean or Cosine similarity as distance measure\n",
    "  * Sklearn: only Euclidean distance is supported  \n",
    "  \n",
    "  # kmeans 对outlier非常敏感, 需要先处理, 或者normalization, 或者对频数进行可视化, 删除高频词= stop word, 低频词 = outlier\n",
    "  \n",
    "  # 在文本处理的distance 需要用cosine similiarity 而不是L2距离\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.1 Load data and generate TF-IDF\n",
    "# Load datasets (http://qwone.com/~jason/20Newsgroups/)\n",
    "# A subset is loaded\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_excel(\"C:/Users/Verdi/OneDrive - stevens.edu/Stevens BIA/660/课件/课件6-clustering/twenty_news_data.xlsx\")\n",
    "\n",
    "# Select three labels for now\n",
    "labels =['comp.graphics', 'soc.religion.christian',\\\n",
    "         'sci.med']\n",
    "data=df[df[\"label\"].isin(labels)]\n",
    "\n",
    "# Split dataset into training and test. \n",
    "# Assuming we only know ground-truth label \n",
    "# for the test set.\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=0) # 如果没有label, 如何测试我们的model分类的好坏.\n",
    "\n",
    "# print out the full text of the first sample\n",
    "print(data[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 1257)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.2\n",
    "# initialize the TfidfVectorizer \n",
    "# set min document frequency to 5\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# set the min document frequency to 5\n",
    "# generate tfidf matrix\n",
    "tfidf_vect = TfidfVectorizer(stop_words=\"english\",\\\n",
    "                             min_df=5) \n",
    "\n",
    "dtm= tfidf_vect.fit_transform(train[\"text\"])\n",
    "print (dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 0, 1, 0, 0, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.3 Clustering using NLTK KMean\n",
    "# cosine distance is calculated\n",
    "\n",
    "from nltk.cluster import KMeansClusterer, \\\n",
    "cosine_distance\n",
    "\n",
    "# set number of clusters\n",
    "num_clusters=3\n",
    "\n",
    "# initialize clustering model\n",
    "# using cosine distance\n",
    "# clustering will repeat 20 times\n",
    "# each with different initial centroids\n",
    "clusterer = KMeansClusterer(num_clusters, \\\n",
    "                            cosine_distance, \\\n",
    "                            repeats=20)\n",
    "\n",
    "# samples are assigned to cluster labels \n",
    "# starting from 0\n",
    "clusters = clusterer.cluster(dtm.toarray(),\n",
    "                             assign_clusters=True)\n",
    " # 聚类函数, 只接受dense array, 不接受sparse array?????\n",
    "    \n",
    "#print the cluster labels of the first 5 samples  #  每次运行的结果都不一样\n",
    "print(clusters[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " edu; nntp; host; posting; graphics; subject; organization; lines; university; thanks; software; com; files; information; washington; file; points; know; video; ca \n",
      "Cluster 1:\n",
      " edu; pitt; gordon; geb; banks; cs; com; article; msg; writes; science; pain; noring; jim; symptoms; subject; health; cancer; reply; organization \n",
      "Cluster 2:\n",
      " god; church; jesus; edu; believe; hell; people; christian; catholic; think; faith; bible; com; christians; question; does; rutgers; life; subject; like \n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.4 Interpret each cluster by centroid\n",
    "\n",
    "# a centroid is the arithemtic mean \n",
    "# of all samples in the cluster\n",
    "# it may not stand for a real document\n",
    "\n",
    "# find top words at centroid of each cluster\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# clusterer.means() contains the centroids\n",
    "# each row is a cluster, and \n",
    "# each column is a feature (word)\n",
    "centroids=np.array(clusterer.means())\n",
    "\n",
    "# argsort sort the matrix in ascending order \n",
    "# and return locations of features before sorting\n",
    "# [:,::-1] reverse the order\n",
    "sorted_centroids = centroids.argsort()[:, ::-1] \n",
    "\n",
    "# The mapping between feature (word)\n",
    "# index and feature (word) can be obtained by\n",
    "# the vectorizer's function get_feature_names()\n",
    "voc_lookup= tfidf_vect.get_feature_names() # \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    \n",
    "    # get words with top 20 tf-idf weight in the centroid\n",
    "    top_words=[voc_lookup[word_index] \\\n",
    "               for word_index in sorted_centroids[i, :20]]\n",
    "    print(\"Cluster %d:\\n %s \" % (i, \"; \".join(top_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# center的最大N个值所在列, 可以作为该类的topic 组成词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. How to evaluate clustering\n",
    "- External evaluation:\n",
    "  - Obtain \"ground truth\": if data is not labeled, manually label a random subset of samples as \"ground truth\" \n",
    "  - Assign each cluster to a \"true\" class by the **majority vote rule**\n",
    "  - Calculate precision and recall\n",
    "  \n",
    "  \n",
    "  | Cluster ID      | Ground Truth Class Label   |\n",
    "  | :------------- |:----------------------------|\n",
    "  | 0      | comp.graphics|\n",
    "  | 1      | sci.med  |\n",
    "  | 2      | soc.religion.christian|\n",
    "  \n",
    "- Internal evaluation\n",
    "  - Silhouette Coefficient\n",
    "  - Calinski-Harabaz Index\n",
    "  - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1, 1, 1, 1, 2, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.2.1 Predict labels for new samples\n",
    "\n",
    "# Question: how to determine \n",
    "# the label for a new sample?\n",
    "\n",
    "# note transform function is used\n",
    "# not fit_transform\n",
    "test_dtm = tfidf_vect.transform(test[\"text\"]) # 直接transform 成tf-idf\n",
    "\n",
    "predicted = [clusterer.classify(v) for v in test_dtm.toarray()]\n",
    "\n",
    "predicted[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    label  cluster\n",
       "0           comp.graphics        0\n",
       "1                 sci.med        1\n",
       "2  soc.religion.christian        0\n",
       "3                 sci.med        1\n",
       "4                 sci.med        1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label    comp.graphics  sci.med  soc.religion.christian\n",
       "cluster                                                \n",
       "0                   21        2                       3\n",
       "1                    0       21                       0\n",
       "2                    0        0                      17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.2.2 External evaluation\n",
    "# determine cluster labels and calcuate precision and recall\n",
    "\n",
    "# Create a dataframe with cluster id and \n",
    "# ground truth label\n",
    "confusion_df = pd.DataFrame(list(zip(test[\"label\"].values, predicted)),\\\n",
    "                            columns = [\"label\", \"cluster\"])\n",
    "confusion_df.head()\n",
    "\n",
    "# generate crosstab between clusters and true labels  = 数据透视表\n",
    "pd.crosstab( index=confusion_df.cluster, columns=confusion_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         comp.graphics       0.81      1.00      0.89        21\n",
      "               sci.med       1.00      0.91      0.95        23\n",
      "soc.religion.christian       1.00      0.85      0.92        20\n",
      "\n",
      "           avg / total       0.94      0.92      0.92        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.2.3 \n",
    "# Map cluster id to true labels by \"majority vote\"\n",
    "cluster_dict={0:'comp.graphics',\\\n",
    "              1:\"sci.med\",\\\n",
    "              2:'soc.religion.christian'}\n",
    "\n",
    "# Map true label to cluster id\n",
    "predicted_target=[cluster_dict[i] \\\n",
    "                  for i in predicted]\n",
    "\n",
    "print(metrics.classification_report\\\n",
    "      (test[\"label\"], predicted_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Clustering with sklearn package - Euclidean distance\n",
    "- Compare its performance with NLTK Kmeans result\n",
    "- Discuss: the difference between performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.3.1 Clustering with sklearn package - Euclidean distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Kmeans with 20 different centroid seeds\n",
    "km = KMeans(n_clusters=num_clusters, n_init=20)\\\n",
    ".fit(dtm)  # NLTK 中n_init = interation.  这里\n",
    "clusters = km.labels_.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    label  cluster\n",
       "0           comp.graphics        1\n",
       "1                 sci.med        1\n",
       "2  soc.religion.christian        1\n",
       "3                 sci.med        1\n",
       "4                 sci.med        1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label    comp.graphics  sci.med  soc.religion.christian\n",
       "cluster                                                \n",
       "0                    0        0                      12\n",
       "1                   21       18                       8\n",
       "2                    0        5                       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.2 Performance Evaluation\n",
    "\n",
    "predicted = km.predict(test_dtm)\n",
    "\n",
    "confusion_df = pd.DataFrame(list(zip(test[\"label\"].values, predicted)),\\\n",
    "                            columns = [\"label\", \"cluster\"])\n",
    "confusion_df.head()\n",
    "\n",
    "# generate crosstab between clusters and true labels\n",
    "pd.crosstab( index=confusion_df.cluster, columns=confusion_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         comp.graphics       0.43      1.00      0.60        21\n",
      "               sci.med       0.00      0.00      0.00        23\n",
      "soc.religion.christian       0.00      0.00      0.00        20\n",
      "\n",
      "           avg / total       0.14      0.33      0.20        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.3.3 Change the mapping accordingly\n",
    "cluster_dict={1:'comp.graphics', 0:\"sci.med\",\\\n",
    "              2:'soc.religion.christian'}\n",
    "\n",
    "# Map true label to cluster id\n",
    "predicted_target=[cluster_dict[i] \\\n",
    "                  for i in predicted]\n",
    "\n",
    "print(metrics.classification_report\\\n",
    "      (test[\"label\"], predicted_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may notice the significant performance difference caused by:\n",
    "   - different distance measures: L2 distance vs. Cosine distance\n",
    "   - high dimensionalties (curse of dimensionality)\n",
    "- What could be possible ways to solve \"curse of dimensionality\"?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. How to pick *K*, the number of clusters?\n",
    "- **Try external valuation first!!!**\n",
    "  - manually assess a subset of documents to create \"ground truth\"\n",
    "- In case it is impossible to figure out how many clusters in the data set manually, **theorectically**, *K* may be selected as follows:\n",
    "  * Select a metric to measure the \"goodness\" of clusters, e.g. average radius, average diameter, etc.\n",
    "  * Varying *K* from 2 to N, perform clustering for each *K*\n",
    "  * Ideally, as *K* increases to some point, the metric should grow slowly (**elbow method**)\n",
    "\n",
    "<img style=\"float: left;\" src='best_k.png'  width='40%'/><img  src='sample1.png' width='30%'/>\n",
    "source: http://infolab.stanford.edu/~ullman/mmds/ch7.pdf\n",
    "- However, if samples do not have clear structures, this method may not work (elbow does not exist!)\n",
    "<img src=\"samples2.png\" width='30%'>\n",
    "\n",
    "# 在类别足够多的时候, 在多的分类, 不会影响类的半径. 因为他们是平行的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
