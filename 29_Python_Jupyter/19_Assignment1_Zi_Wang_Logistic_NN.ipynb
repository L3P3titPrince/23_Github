{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.Summary\"></a>\n",
    "# 1.Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Classifcation. You need to classify text paragraphs into three categories: Fyodor Dostoyevsky, Arthur Conan Doyle, and Jane Austen by building your own classifers. The data provided is from Project Gutenberg.\n",
    "Most of parts have been writen into function. But for the final <code>__main__ </code>part, there are still some parts write didn't that well. Need future improvement.\n",
    "<code>Logistci Regressan, Mini-batch and Stochasitc gradient descent</code> didn't use packages. Others, including <code>Neural Network</code> used packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.Contents\"></a>\n",
    "# 2.Contents\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><a href=\"#1.Summary\">Summary</a></li>\n",
    "    <li><a href=\"#2.Contents\">Contents</a></li>\n",
    "    <li><a href=\"#3.Construct examples\">Construct examples</a></li>\n",
    "    <li><a href=\"#4.Preprocess data\">4.Preprocess data / Feature Extraction</a></li>\n",
    "    <li><a href=\"#5.Data split\">Data split</a></li>\n",
    "    <li><a href=\"#6.Train\">Train</a></li>\n",
    "    <ul>\n",
    "       <li><a href=\"#6.1 Gradien Descent\">6.1 Gradien Descent</a></li>\n",
    "       <li><a href=\"#6.2 Mini-batch Gradient Descent\">6.2 Mini-batch Gradient Descent</a></li> \n",
    "       <li><a href=\"#6.3 stochastic gradient descent\">6.3 stochastic gradient descent</a></li>\n",
    "       <li><a href=\"#6.4 Multilayer Perceptron\">6.4 Multilayer Perceptron</a></li> \n",
    "    </ul>\n",
    "    <li><a href=\"#7.Main\">Main</a></li>\n",
    "    <li><a href=\"#8.Cross-validation\">Cross-validation</a></li>\n",
    "    <li><a href=\"#9.Plot\">Plot</a></li>\n",
    "    <li><a href=\"#10.Compare Conclusion\">Compare Conclusion</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 437\n"
     ]
    }
   ],
   "source": [
    "#if you want to rebuild identical environment, you can install follow this requirments\n",
    "!conda list --export > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#we need use bs4 to eliminate html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#it seems not working well\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#for the neural network part, we need use tensorflow and keras as backend\n",
    "from tensorflow import keras\n",
    "#keras only can complete simple text preprocess work\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, \\\n",
    "Dropout, Activation, Input, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#this function is used to monitor \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.Construct examples\"></a>\n",
    "# 3.Construct examples\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divde each document into multiple paragramps. Each graph will be one example, one element in list. Text in the begining to demenstrate info will be discarded. All data will be formed into a DataFrame, which have \"AUTHOR\" and \"CLASSIFY\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import():\n",
    "    \"\"\"\n",
    "    Each text have different issues, so i can not use one function to process all raw data\n",
    "    \n",
    "    Return:\n",
    "    --------\n",
    "    df:DataFrame\n",
    "        concatenate all data into one DataFrame and add column name\n",
    "    data_1:list\n",
    "        from Fyodor Dostoyevsky,\n",
    "    data_2:list\n",
    "        from Arthur Conan Doyle,\n",
    "    data_3:list\n",
    "        from Jane Austen\n",
    "    \"\"\"\n",
    "    #Due to txt contain 'gbk', we have to read this file as binary code style, but binary leave more issues\n",
    "    with open('03_data/11_Project Gutenberg Data/28054-0.txt', 'rb') as f:\n",
    "        #First we use normal read\n",
    "        #Second, we should decode binary with utf-8, which will turn binary back to string\n",
    "        #Thrid, we need split raw text into paragraph, according to data, \n",
    "        #every paragraph are seperated by '\\r\\n\\r\\n'\n",
    "        #In binary new line is\"\\r\\n\\r\\n\". In string new line is \"\\n\\n\"\n",
    "        lines_1 = f.read().decode('utf-8').split('\\r\\n\\r\\n')\n",
    "    #we only need main content, so eliminate header of each raw data. \n",
    "    #We only keep content from first paragraph title\n",
    "    index_1 = lines_1.index('Chapter I. Fyodor Pavlovitch Karamazov')\n",
    "    data_1 = lines_1[index_1+1:]\n",
    "    while(\"\" in data_1) : \n",
    "        data_1.remove(\"\") \n",
    "    print(f'For category one, Fyodor Dostoyevsky, we have {len(data_1)} examples')\n",
    "    \n",
    "    \n",
    "    #lines_2 can read directly\n",
    "    with open('03_data/11_Project Gutenberg Data/pg1661.txt') as f:\n",
    "        #we can use '\\n\\n' to split paragraph\n",
    "        lines_2 = f.read().split('\\n\\n')\n",
    "    #we only want main content of this book\n",
    "    index_2 = lines_2.index('\\nADVENTURE I. A SCANDAL IN BOHEMIA') \n",
    "    #due to technical reason, i can't elimiate some extra paragraph, so we add two after index\n",
    "    data_2 = lines_2[index_2+2:]\n",
    "    while(\"\" in data_2) : \n",
    "        data_2.remove(\"\") \n",
    "    print(f'For category two, Arthur Conan Doyle, we have {len(data_2)} examples')\n",
    "    \n",
    "    \n",
    "    with open('03_data/11_Project Gutenberg Data/pg31100.txt',  'rb') as f:\n",
    "        lines_3 = f.read().decode('utf-8').split('\\r\\n\\r\\n')\n",
    "    index_3 = lines_3.index('\\r\\nChapter 1')\n",
    "    data_3 = lines_3[index_3+1:]\n",
    "    while(\"\" in data_3) : \n",
    "        data_3.remove(\"\") \n",
    "    print(f'For category three, Fyodor Dostoyevsky, we have {len(data_3)} examples')\n",
    "    \n",
    "    #it's more convient to transform data into pandas DataFrame\n",
    "    data = {'AUTHOR':data_1+data_2+data_3, 'CLASSIFY':[1]*len(data_1)+[2]*len(data_2)+[3]*len(data_3)}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(0,len(lines_1)):\n",
    "        try:\n",
    "            lines_3[i] = lines_3[i].decode('utf-8')\n",
    "    except:\n",
    "        #n+=1\n",
    "    print(\"'ascii' codec can't decode byte 0xe2 in position 47: ordinal not in\")\n",
    "    f.close()\n",
    "    \"\"\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.Preprocess data\"></a>\n",
    "# 4.Preprocess data / Feature Extraction\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation, irrelevant symbols, urls, and numbers. You can remove the unrelated text in the beginning of each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have two way to complete preprocessing progress. One is using keras.preprocess, another is using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(text):\n",
    "    \"\"\"\n",
    "    The reason i use seperate function is that pandas.apply can manipulate with column value. \n",
    "    If we use loop directly, we will get a join corpus without paragraph structure\n",
    "    \"\"\"\n",
    "    no_pun = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_pun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    \"\"\"\n",
    "    Use bs4 to extract text\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    no_html = soup.get_text()\n",
    "    return no_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_regex(text):\n",
    "    \"\"\"\n",
    "    It was designed to remove punctuation, but we can't manipulate with non string effectively\n",
    "    \"\"\"\n",
    "    #remove url\n",
    "    no_reg = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    #remove numbers\n",
    "    no_reg = re.sub('\\w*\\d\\w*', '', no_reg)\n",
    "    return no_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df, vectorizer=None):\n",
    "    \"\"\"\n",
    "    we use this function to complete preprocessing cleaning and tfidf function. Becuase we have to mentain \n",
    "    the relationship between corpus and his lable, we have several times list to DataFrame processes.\n",
    "    I didn't show EDA part for setting up \n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    df:pandas.DataFrame\n",
    "        DataFrame, contain ['AUTHOR'] and ['CLASSIFY']. This is raw data.\n",
    "        \n",
    "    vectorizer:cofig\n",
    "        When we apply to \n",
    "            \n",
    "    Return:\n",
    "    -------\n",
    "    X_vector:array\n",
    "        Dimension = (cleaned example, MAX_LEN).Cleaned data and transformed to TFIDF format \n",
    "        with original sequence, which means can be matched withcooresponding y_labels.\n",
    "        \n",
    "    y_vector:\n",
    "        Dimension = (no. cleaned examples, NUM_LABELS)=(9630,3)\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    MAX_LEN = 10000\n",
    "    \n",
    "    #tokens = corpus.apply(lambda x: x.split())\n",
    "    #tokens = word_tokenize(tokens)\n",
    "    #tokens = word_tokenize(corpus.str)\n",
    "    \n",
    "    #Stemming and Lemmatizing:   \n",
    "    #Coreference resolution\n",
    "    \n",
    "    #original datatype is serise, first transfrom to string and get lower() case text\n",
    "    corpus_2 = df['AUTHOR'].str.lower()\n",
    "    \n",
    "    #using bs4 to eliminate html\n",
    "    #soup = BeautifulSoup(corpus_2, 'lxml')\n",
    "    #corpus_3 = soup.get_text()\n",
    "    corpus_3 = corpus_2.apply(lambda x: remove_html(x))\n",
    "    \n",
    "    \n",
    "    #any speical punctuation in filter sring should add \"\\\" before it\n",
    "    #corpus_3 = re.sub('\\[.*?\\]', '', corpus_2.to_string)\n",
    "    #corpus_2.str.replace('\\\\r','',regex=True)\n",
    "    #!\"#$%&()*\\+,-./:;<=>\\?@\\[\\\\\\]^_`{|}~\\\\t\\\\n\\\\r\\“\n",
    "    corpus_4 = corpus_3.apply(lambda x: remove_regex(x))\n",
    "    \n",
    "    #use sring.puncutation to eliminate, but we should first remove url. I believe this should be last step\n",
    "    corpus_5 = corpus_4.apply(lambda x: remove_pun(x))\n",
    "    \n",
    "    #only reserve words\n",
    "    pattern=r'[a-zA-Z][-._a-zA-Z]*[a-zA-Z]'\n",
    "    corpus_6 = [\" \".join(re.findall(pattern, x)) for x in corpus_5]\n",
    "    \n",
    "    #we sitll need to manipulate with index because it contain important relationship between corpus and claasify\n",
    "    #list to pd.Series\n",
    "    corpus_7 = pd.Series(np.array(corpus_6))\n",
    "    #extract classify column\n",
    "    classify_col = df['CLASSIFY']\n",
    "    #build a new data dictionary for generating DataFrame\n",
    "    data_2 = {'AUTHOR':corpus_7, 'CLASSIFY':classify_col}\n",
    "    #build a dataFrame with AUTHOR and CLASSIFY infomation. For now, the index of df and corpus_8 are identical\n",
    "    corpus_8 = pd.DataFrame(data_2)\n",
    "    \n",
    "    \n",
    "    #we can't directly drop column because index will dynamicly decrease, but we can gather index of drop\n",
    "    index_drop=[]\n",
    "    #iteration through all DataFrame\n",
    "    for i in range(len(corpus_8)):\n",
    "        #according to plot and statitc result,>600 have 2628, <60 have 3540, so we only need 60<data<600\n",
    "        if len(corpus_8.iloc[i,0])<60 or len(corpus_8.iloc[i,0])>600:\n",
    "            #delete too big and too small\n",
    "            index_drop.append(i)\n",
    "    print(f\"before drop shape={corpus_8.shape}\")\n",
    "    \n",
    "    #drop row by list but remain old index number\n",
    "    corpus_9 = corpus_8.drop(index_drop,axis=0)\n",
    "    print(f\"after drop shape={corpus_9.shape}\")\n",
    "    #re.finall(\\w+)  \n",
    "    \n",
    "    #inintial \n",
    "\n",
    "    if vectorizer == None:\n",
    "        vectorizer = TfidfVectorizer(stop_words='english',max_features = MAX_LEN)\n",
    "        #when we built a vect, we need to import all words as corpus combination to generate a TFIDF dictornary\n",
    "        vect = vectorizer.fit([\" \".join(corpus_9['AUTHOR'].tolist())])\n",
    "        #after fit, we need to use dictionary to transform our coupus into TFIDF(we can use sum() to check sparse)\n",
    "        data_2 = vect.transform(corpus_9['AUTHOR']).toarray()\n",
    "        X_vector = np.array(data_2)\n",
    "    else:\n",
    "        vect = vectorizer.fit([\" \".join(corpus_9['AUTHOR'].tolist())])\n",
    "        #after fit, we need to use dictionary to transform our coupus into TFIDF(we can use sum() to check sparse)\n",
    "        X_vector = vect.transform(corpus_9['AUTHOR']).toarray()\n",
    "\n",
    "    #To remain the relation between AUTHOR vector and CLASSIFY labels, we also output y_vector coorespondingly\n",
    "    y_vector = mapped(corpus_9['CLASSIFY'])\n",
    "#     data=None\n",
    "#     vect=None\n",
    "    return corpus_9, X_vector, y_vector, vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#This part is used for verify processing result\\n#this will show which vector was transfromed back to words. We use this output to compare with corpus[0]\\n#for instance, we can check data[5] related to corpus_9[5]. Except stopwords, they have same stem words\\n\\ncorpus_9, X_test_1, y_test_1, vect = tfidf(df)\\nvect.inverse_transform(data_4)[0]\\ncorpus[0]\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#This part is used for verify processing result\n",
    "#this will show which vector was transfromed back to words. We use this output to compare with corpus[0]\n",
    "#for instance, we can check data[5] related to corpus_9[5]. Except stopwords, they have same stem words\n",
    "\n",
    "corpus_9, X_test_1, y_test_1, vect = tfidf(df)\n",
    "vect.inverse_transform(data_4)[0]\n",
    "corpus[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.Data split\"></a>\n",
    "# 5.Data split\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split data equally into three pieces. Train 60%, Calidation 20%, Test 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X_vector,y_vector, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df:DataFrame\n",
    "        This is coming from data_import. This is still raw data with corpus inside. After data split\n",
    "        tfidf() function will complete data preprocess\n",
    "        \n",
    "    test_size:float\n",
    "        you can change percentage\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vector, y_vector, \\\n",
    "                                                        test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, label):\n",
    "    \"\"\"\n",
    "    This function is used to split data into three part, 60% as traning, 20%as validataion and 20% as test\n",
    "    In this part we still manipulate raw corpus, not vector result\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df:pd.DataFrame\n",
    "        Contain column 'AUTHOR' and 'CLASSIFY'\n",
    "        \n",
    "        \n",
    "    Return:\n",
    "    ----------\n",
    "    train_X:\n",
    "    validation_X:\n",
    "    test_X:\n",
    "    train_y:\n",
    "    validation_y:\n",
    "    test_y:\n",
    "    \n",
    "    \"\"\"\n",
    "    #we can arrange percentage in this place\n",
    "    m = data.shape[0]\n",
    "    training_size = int(m * 0.6)\n",
    "    validation_size = int(m * 0.8)\n",
    "    print(f'Split data into three parts 0-{training_size} is train_part.\\n')\n",
    "    print(f'{training_size}-{validation_size} is validation_part.\\n')       \n",
    "    print(f'{validation_size}-{m} is test_part.\\n')\n",
    "    \n",
    "    train_X = data[0:training_size]\n",
    "    validation_X = data[training_size:validation_size]\n",
    "    test_X = data[validation_size:]\n",
    "    train_y = label[0:training_size]\n",
    "    validation_y = label[training_size:validation_size]\n",
    "    test_y = label[validation_size:]\n",
    "\n",
    "    \n",
    "    return train_X, validation_X, test_X, train_y, validation_y, test_y\n",
    "\n",
    "#train_X, validation_X, test_X, train_y, validation_y, test_y = data_split(data_1, label_1)\n",
    "\n",
    "def concatenate_df(df):\n",
    "    \"\"\"\n",
    "    This function is used to merge train/validatoin/test with three different classfy\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    #\n",
    "    data_1 = df.loc[df['CLASSIFY']==1]['AUTHOR']\n",
    "    label_1 = df.loc[df['CLASSIFY']==1]['CLASSIFY']\n",
    "    data_2 = df.loc[df['CLASSIFY']==2]['AUTHOR']\n",
    "    label_2 = df.loc[df['CLASSIFY']==2]['CLASSIFY']\n",
    "    data_3 = df.loc[df['CLASSIFY']==3]['AUTHOR']\n",
    "    label_3 = df.loc[df['CLASSIFY']==3]['CLASSIFY']\n",
    "    \n",
    "    #caculate each part of DataFrame\n",
    "    train_X1, validation_X1, test_X1, train_y1, validation_y1, test_y1 = data_split(data_1, label_1)\n",
    "    train_X2, validation_X2, test_X2, train_y2, validation_y2, test_y2 = data_split(data_2, label_2)\n",
    "    train_X3, validation_X3, test_X3, train_y3, validation_y3, test_y3 = data_split(data_3, label_3)\n",
    "    \n",
    "    train_X = pd.concat( [train_X1, train_X2, train_X3] )\n",
    "    train_y = pd.concat( [train_y1, train_y2, train_y3] )\n",
    "    data = {'AUTHOR':train_X, 'CLASSIFY':train_y}\n",
    "    train_df = pd.DataFrame(data)\n",
    "    #validataion_X = pd.concat( [validation_X1, validation_X2, validation_X3] )\n",
    "    #test_X = \n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6.Train\"></a>\n",
    "# 6.Train\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6.1 Gradien Descent\"></a>\n",
    "### 6.1 Logistic Regression Gradien Descent\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a Logistic Regression (LR) model with L2 regularization from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    z = np.dot(x, theta)\n",
    "    \"\"\"\n",
    "    #z = z - np.max(z)\n",
    "    sm = np.exp(z)/ np.sum(np.exp(z))\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_shift(z):\n",
    "    \"\"\"\n",
    "    https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n",
    "    \"\"\"\n",
    "    shift_z = z - np.max(z)\n",
    "    sm = np.exp(shift_z) / np.sum(np.exp(shift_z))\n",
    "    \n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped(y):\n",
    "    \"\"\"\n",
    "    one-hot vector classifier\n",
    "    \"\"\"\n",
    "    #we set label dimension as (m, num_labels)\n",
    "    NUM_LABELS = 3\n",
    "    m=y.shape[0]\n",
    "    y_mapped=np.zeros((m, NUM_LABELS))\n",
    "    #Due to y is DataFrame, we need to manipulate it with .iloc[]\n",
    "    #y.iloc[i] = 1/2/3 which is not convinent index of columns(0-2), so we need minus 1, which menas 1/2/3 will appear ONE at 0/1/2 postion\n",
    "    for i in range(0,m):\n",
    "        y_mapped[i, y.iloc[i]-1]=1;\n",
    "    \n",
    "    return y_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_cost(X_t, y, theta, lr, lambda_t):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X_t:matrix\n",
    "        (m, 10000) 10000 is MAX_LEN max features\n",
    "        \n",
    "    y_t:matrix\n",
    "        (m, 3) with one-hot vector to represent \n",
    "        \n",
    "    theta_t:matrx\n",
    "        should be MAX_LEN+1 = features + bias (MAX_LEN+1, NUM_LABELS)\n",
    "    \n",
    "    \"\"\"\n",
    "    NUM_LABELS = 3\n",
    "    #m = number of exmaples, n = number of features\n",
    "    [m,n] = X_t.shape\n",
    "    #print(type(m))\n",
    "    #the input has benn transposed into one-hot form\n",
    "    \n",
    "    #initial J value\n",
    "    J = 0\n",
    "    #and bias for X. np.ones create a (m,1) column vector add before X_t as a column operation(axis=1)\n",
    "    #i think we still need add bias in this NLP problems\n",
    "    #X_bias = (m, n+1) = (m, 10001)\n",
    "    X_bias = np.concatenate( (np.ones((m,1)),X_t), axis=1 )\n",
    "    #print(f'shape of X_bias = {X_bias.shape}')\n",
    "    \n",
    "    #initial theta as matrix, first dimentsion is number of features, second is NUM_LABEls\n",
    "    #theta = np.ones((n+1,NUM_LABELS))\n",
    "    #print(f'shape of theta = {theta.shape}')\n",
    "    \n",
    "    #hx is our hypothyesis function, x=(m,n+1) theta=(n+1,3) so hx = (m, 3)\n",
    "    hx = softmax_shift(np.dot(X_bias, theta))\n",
    "    #print(f'shape of hx = {lambda_t}')\n",
    "    \n",
    "    #y=(m,3), (3,m)*(m,3)\n",
    "    #add L2 regulation, but only sum w WITHOUT bias, so we only caculate row after first row(first row is bias)\n",
    "    J = (-1/m) * np.sum( np.dot( np.transpose(y), np.log(hx)) ) + \\\n",
    "        (lambda_t/(2*m)) * np.sum(theta[1:,:]**2)\n",
    "    \n",
    "    #we need to caculate bias grad and theta seperately\n",
    "    grad = np.zeros((n+1, NUM_LABELS))\n",
    "    #only caculate bias, only first row is our bias\n",
    "    #X_bias[:,0] =(m,1) (hx-y)=(m,3) so np.dot=(1,m)*(m,3) = grad[0,:]\n",
    "    grad[0,:] = (-1/m) * np.dot( np.transpose(X_bias[:,0]),(hx -y)) \n",
    "    \n",
    "    #updata other parameters\n",
    "    grad[1:,:] = (-1/m) * np.dot( np.transpose(X_bias[:,1:]),(hx-y) ) + lambda_t/m * theta[1:,:]\n",
    "    \n",
    "    new_theta = theta - lr*grad\n",
    "    \n",
    "    #****************Predicat part******************************8\n",
    "    #because theta is include bias, so we still need add bias\n",
    "    #find the max of each example/row. we transfor all label into same format\n",
    "    y_hat = softmax_shift(np.dot(X_bias, new_theta))\n",
    "    pred = np.argmax(y_hat, axis=1)\n",
    "    ground_truth = np.argmax(y, axis = 1)\n",
    "\n",
    "    #if pred and ground_truth have same result, sum them and divide by total number of example\n",
    "    accuracy = sum(pred == ground_truth)/(float(m))\n",
    "    \n",
    "    return J, grad, new_theta, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_,_, new_theta, acc = LR_cost(X_train, y_train, theta, lr=1-3, lambda_t=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_initial(X):\n",
    "    [m,n] = X.shape\n",
    "    NUM_LABELS = 3\n",
    "    theta = np.random.randn(n+1,NUM_LABELS)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr, epochs, theta):\n",
    "    [m,n] = X.shape\n",
    "    NUM_LABELS = 3\n",
    "    #initial theta as matrix, first dimentsion is number of features, second is NUM_LABEls\n",
    "    #theta = np.random.randn(n+1,NUM_LABELS)\n",
    "    \n",
    "    J_history=[]\n",
    "    grad_history=[]\n",
    "    theta_history=[]\n",
    "    for i in range(0,epochs):\n",
    "        J, grad, theta, accuracy = LR_cost(X, y, theta, lr, lambda_t=1) \n",
    "        \n",
    "        J_history.append(J)\n",
    "        theta_history.append(theta)\n",
    "        grad_history.append(grad)\n",
    "        \n",
    "    return theta_history, J_history, grad_history, theta\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = theta_initial(X_vector_train)\n",
    "# theta_history, J_history,grad_history, theta= gradient_descent(X_vector_train, y_vector_train, 0.03, 30, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6.2 Mini-batch Gradient Descent\"></a>\n",
    "### 6.2 Mini-batch Gradient Descent\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(X,y, batch_size):\n",
    "    \"\"\"\n",
    "    mini_batch is extract 'batch_size' part of data one by one through the data order.\n",
    "    For instacne, extract 32(batch_size) from 1000(examples), Typically, we can't exact division, so we let \n",
    "    the reminder, which size will be smaller than batch_size, to be the last iteration batch part\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    X:array-like\n",
    "        Input X will be vector with shape (m,n) m=number of exmaples and n=number of features.\n",
    "        In this exmaple, we might imput a (6093, 10000) dimension.\n",
    "    y:array-like\n",
    "        Input y will be vector with shape (m,NUM_LABELS) NUM_LABLES=number of labels, for example, 10 classifiers\n",
    "        In this example, we might input a (6093, 3) dimension matrix\n",
    "        \n",
    "        \n",
    "    batch_size:int\n",
    "        typically is 2^n result\n",
    "      \n",
    "    Return:\n",
    "    -------\n",
    "    X_batch_list:list\n",
    "        list of array, which contain (batch_size, 10000) dimension. Len(list) is depend on m//batch_size\n",
    "        \n",
    "    y_batch_list:list\n",
    "        list of array, which consist of (batch_size, 3) dimension\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    #size of examples\n",
    "    m = X.shape[0]\n",
    "    X_batch_list = []\n",
    "    y_batch_list = []\n",
    "    #print(m//batch_size)\n",
    "    #ignore the decimal part，only reserve the integer part, we use this floor divsion result to build a \n",
    "    #loop and add index number into a list\n",
    "    for i in range(m//batch_size):\n",
    "        #print(i)\n",
    "        X_batch_list.append( X[i*batch_size:(i+1)*batch_size,:])\n",
    "        y_batch_list.append( y[i*batch_size:(i+1)*batch_size,:])\n",
    "    #if m divison batch_size have a remainder, we should add the reaming into the mini_batch list loop\n",
    "    if m % batch_size > 0:\n",
    "        X_batch_list.append( X[m//batch_size * batch_size:, :])\n",
    "        y_batch_list.append( y[m//batch_size * batch_size:, :])\n",
    "        \n",
    "    #mini_batches = []\n",
    "    #join X and y into one np.array\n",
    "    #data = np.hstack( (X,y) )\n",
    "    #shuffle the data and let pick more random\n",
    "    #np.random.shuffle(data)\n",
    "    #print(type(data))\n",
    "    #print(data.shape)\n",
    "    #m = number of examples / batch_size\n",
    "    #m = data.shape[0]\n",
    "    \n",
    "    #idk why we need plus 1 in here\n",
    "    #for i in range(m+1):\n",
    "        #the first mini_batch should be the first block of data of mini_batch_size, which is [0,batch_size]\n",
    "        #mini_batch = data[i * batch_size:(i+1)*batch_size,:]\n",
    "\n",
    "    return X_batch_list, y_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_GD(X_batch_list, y_batch_list, theta, lambda_t, \\\n",
    "                  lr=1e-3, decay_factor=0.99, epochs=10, \\\n",
    "                  optimizer='mini_batch', epsilon = 1e-1):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_batch_list:list\n",
    "        list of array. This is set of all batched X_train data. one list is one batch\n",
    "        \n",
    "    y_batch_list:list\n",
    "        list of array. consist of each batch_sized (32, 3) array\n",
    "        \n",
    "    lr:float\n",
    "        learning rate, classical numerical is 0.01\n",
    "    \n",
    "    decay_factor:float\n",
    "        we use decay_factor to reduce learning rate step by step. Classical numerical is 0.99\n",
    "        \n",
    "    lambda_t:float\n",
    "        parameters for L2 regulaizaion \n",
    "        \n",
    "    epochs:int\n",
    "        iteration numbers\n",
    "        \n",
    "    X:array\n",
    "        original dataset\n",
    "        \n",
    "    optimizer:string\n",
    "        default is \"mini_batch\", use this paramter to switch between \"mini_batch\" and \"SGD\"\n",
    "    \n",
    "    epsilon:float\n",
    "        SGD use epsilon to stop convergence\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    [m,n] = X_vector.shape\n",
    "    \n",
    "    #print(f\"Current Lambda:{lambda_t}\")\n",
    "    J_history=[]\n",
    "    theta_history=[]\n",
    "    grad_history=[]\n",
    "    acc_history=[]\n",
    "   \n",
    "    if optimizer =='mini_batch':\n",
    "        for j in tqdm(range(epochs)):\n",
    "            #everytime we need random our data pool before we start next epochs. \n",
    "            #If we didn't shuffle our data pool, we may face non convergence gradient descent\n",
    "            #we generate a list from 0 to len(X_batch_list) and shuffle it. \n",
    "            #This type of random can make sure all batch can be used\n",
    "            idx = np.arange(len(X_batch_list))\n",
    "            np.random.shuffle(idx)\n",
    "            #reconstrcution batch_list from new random index, every epochs we will use new idx\n",
    "            X_batch_list = [X_batch_list[i] for i in idx]\n",
    "            y_batch_list = [y_batch_list[i] for i in idx]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            #another way\n",
    "            idx = np.random.randint(0, len(X_batch_list), len(X_batch_list))\n",
    "            \"\"\"\n",
    "            \n",
    "            #update lr to smaller through epochs\n",
    "            #for now i only use decay_factor to slowly decrease, for the future, i need to use \n",
    "            #learning optimizer and built learning rate matrix to update lr for each parameters\n",
    "            lr = lr*decay_factor\n",
    "            for i in range(len(X_batch_list)):\n",
    "                #extract every piece size batch to caculate cost function\n",
    "                X_batch = X_batch_list[i]\n",
    "                y_batch = y_batch_list[i]\n",
    "\n",
    "                J, grad,theta, accuracy = LR_cost(X_batch, y_batch, theta, lr, lambda_t) \n",
    "\n",
    "                J_history.append(J)\n",
    "                theta_history.append(theta)\n",
    "                grad_history.append(grad)\n",
    "                acc_history.append(accuracy)\n",
    "                \n",
    "    #stochastic gradient descent, the only different is that we should use epsilon to stop iteration\n",
    "    elif optimizer =='sgd':\n",
    "        for j in tqdm(range(epochs)):\n",
    "            #everytime we need random our data pool before we start next epochs. \n",
    "            #If we didn't shuffle our data pool, we may face non convergence gradient descent\n",
    "            #we generate a list from 0 to len(X_batch_list) and shuffle it. \n",
    "            #This type of random can make sure all batch can be used\n",
    "            idx = np.arange(len(X_batch_list))\n",
    "            np.random.shuffle(idx)\n",
    "            #reconstrcution batch_list from new random index, every epochs we will use new idx\n",
    "            X_batch_list = [X_batch_list[i] for i in idx]\n",
    "            y_batch_list = [y_batch_list[i] for i in idx]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            #another way\n",
    "            idx = np.random.randint(0, len(X_batch_list), len(X_batch_list))\n",
    "            \"\"\"\n",
    "            \n",
    "            #update lr to smaller through epochs\n",
    "            #for now i only use decay_factor to slowly decrease, for the future, i need to use \n",
    "            #learning optimizer and built learning rate matrix to update lr for each parameters\n",
    "            lr = lr*decay_factor\n",
    "            for i in range(len(X_batch_list)):\n",
    "                #extract every piece size batch to caculate cost function\n",
    "                X_batch = X_batch_list[i]\n",
    "                y_batch = y_batch_list[i]\n",
    "                \n",
    "                theta_old = theta\n",
    "                J, grad,theta, accuracy = LR_cost(X_batch, y_batch, theta, lr, lambda_t) \n",
    "\n",
    "                J_history.append(J)\n",
    "                theta_history.append(theta)\n",
    "                grad_history.append(grad)\n",
    "                acc_history.append(accuracy)\n",
    "                \n",
    "                #\n",
    "                if np.abs(theta_old - theta).sum()<epsilon:\n",
    "                    print('Early stop')\n",
    "                    break\n",
    "                \n",
    "    else:\n",
    "        print(\"Please enter your algothem choice\")\n",
    "    \n",
    "    return J_history, theta_history, acc_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************TEST SECTION*******************88\n",
    "# X_batch_list, y_batch_list = mini_batch(X_train, y_train, batch_size =8)\n",
    "# J_history_valid, theta_history_valid, acc_history_valid = mini_batch_GD(X_batch_list, y_batch_list, theta, \\\n",
    "#                                                    lambda_t=0.1, X_train=X_train, y_train=y_train, \\\n",
    "#                                                     lr=1e-3, decay_factor = 0.99, \\\n",
    "#                                                     epochs=30, \\\n",
    "#                                                    optimizer='mini_batch', epsilon = 1e-1)\n",
    "\n",
    "# plt.plot(range(len(J_history_valid)), J_history_valid)\n",
    "\n",
    "\n",
    "\n",
    "# y_hat, pred, ground_truth, accuracy = predict(theta)\n",
    "# accuracy\n",
    "# class MiniBatch(Object):\n",
    "#     def __init___(self):\n",
    "        \n",
    "#     def algo(slef, fit):\n",
    "#         self.fit=mini_batch_GD()\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6.3 stochastic gradient descent\"></a>\n",
    "### 6.3 stochastic gradient descent\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_GD(X_vector, y_vector, theta, lr, \\\n",
    "           decay_factor=0.99, lambda_t=0.1, epochs=10, epsilon = 1e-1):\n",
    "    \"\"\"\n",
    "    Theoretically, sgd is simple version of mini-batch, we set mini-batch=1\n",
    "    \n",
    "    \"\"\"\n",
    "    [m,n] = X_vector.shape\n",
    "    J_history=[]\n",
    "    theta_history=[]\n",
    "    grad_history=[]\n",
    "    acc_history=[]\n",
    "    for i in tqdm(range(epochs)):\n",
    "        #generate a random idx and select it from whole train corpus\n",
    "        random_idx = np.random.randint(0, m)\n",
    "        X_i = X_vector[random_idx,:]\n",
    "        y_i = y_vector[random_idx,:]\n",
    "\n",
    "        #update lr to smaller through epochs\n",
    "        #for now i only use decay_factor to slowly decrease, for the future, i need to use \n",
    "        #learning optimizer and built learning rate matrix to update lr for each parameters\n",
    "        lr = lr*decay_factor\n",
    "        theta_old = theta\n",
    "        J, grad,theta, accuracy = LR_cost(X_vector, y_vector, theta, lr, lambda_t) \n",
    "        \n",
    "        J_history.append(J)\n",
    "        theta_history.append(theta)\n",
    "        grad_history.append(grad)\n",
    "        acc_history.append(accuracy)\n",
    "        \n",
    "        #if difference between old and new theta is smaller than epsilon (1e-3), then stop \n",
    "        if np.abs(theta_old - theta).sum()<epsilon:\n",
    "            print('Early stop')\n",
    "            break\n",
    "    return J_history, theta_history, acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6.4 Multilayer Perceptron\"></a>\n",
    "### 6.4 Multilayer Perceptron\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Neural Network Mode\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    X_train:array-like\n",
    "        n / NUM_FEATURES = 10000 = MAX_DOC_LEN. This paramters is decided by tfidf function\n",
    "    \"\"\"\n",
    "    #this hyperparamter linkage with tfidf() function\n",
    "    MAX_DOC_LEN = 10000\n",
    "    #because this is three classify problem\n",
    "    NUM_LABLES =3\n",
    "    \n",
    "    #*****************model built******************************\n",
    "    input_layer = Input(shape=(MAX_DOC_LEN,), dtype='float32', name='input_layer')\n",
    "    #\n",
    "    dense_layer_1 = Dense(1024, activation='relu', name='dense_1')(input_layer)\n",
    "    dense_layer_2 = Dense(64, activation='relu',name=\"dense_2\")(dense_layer_1)\n",
    "    #Due to multi-classify problem, we choose softmax as our output activation function\n",
    "    output_layer = Dense(NUM_LABLES, activation='softmax',name=\"output\")(dense_layer_2)\n",
    "    model_a = Model(inputs=input_layer, outputs=output_layer, name='model_a')\n",
    "    model_a.summary()\n",
    "    #***************model built****************************\n",
    "    \n",
    "    \n",
    "    dot_img_file = '04_images/10_model.png'\n",
    "    tf.keras.utils.plot_model(model_a, to_file=dot_img_file, show_shapes=True)\n",
    "    model_a.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model_a.fit(X_train, \\\n",
    "                          y_train, \\\n",
    "                            epochs = 30, \\\n",
    "                            validation_data = (X_valid, y_valid), \\\n",
    "                            verbose = 1\n",
    "                           )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test section\n",
    "# NN_history = {dic[0]:history.history['val_loss'], \\\n",
    "#               dic[1]:history.history['loss'], \\\n",
    "#               dic[2]:history.history['accuracy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7.Main\"></a>\n",
    "# 7.Main Function\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flollowing is the processing sequence:\n",
    "<ol>\n",
    "    <li>Construct examples. This step will output DataFrame with <code>AUTHOR</code> and <code>CLASSIFY</code></li>\n",
    "    <li>Preprocess Data. This step contain feature extraction (TFIDF).And we get vector result </li>\n",
    "    <li>Data Split.</li>\n",
    "    <li>Train in LR model</li>\n",
    "    <li>Train in NN model</li>\n",
    "    <li>Cross-validation</li>\n",
    "    <li>Plot</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For category one, Fyodor Dostoyevsky, we have 6039 examples\n",
      "For category two, Arthur Conan Doyle, we have 2590 examples\n",
      "For category three, Fyodor Dostoyevsky, we have 11105 examples\n",
      "before drop shape=(19734, 2)\n",
      "after drop shape=(12038, 2)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #********Step1.Construct examples**********\n",
    "    df = data_import()\n",
    "    #********Step2.Clean Data*******************\n",
    "    corpus_train, X_vector, y_vector, vect_train = tfidf(df)\n",
    "    #****************Step3.Data split**************\n",
    "    X_train, X_test, y_train, y_test = split(X_vector, y_vector, 0.2)\n",
    "        \n",
    "    #*************************NEED OPTIMIZE********************\n",
    "    theta = theta_initial(X_train)\n",
    "    #*************************NEED OPTIMIZE***********************\n",
    "#     #Preprocess Data\n",
    "#     corpus_train, X_vector_train, y_vector_train, vect_train = tfidf(X_train)\n",
    "    \n",
    "#     corpus_test, X_vector_test, vect_train = tfidf(X_test, vectorizer=vect_train)\n",
    "#     y_vector_test = mapped(y_test)\n",
    "#     theta_history, J_history, grad_history, theta_old= gradient_descent(X_vector_train, y_vector_train, \\\n",
    "#                                                                         0.1, 5, theta)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8.Cross-validation\"></a>\n",
    "# 8.Cross-validation\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X_vector=X_train, y_vector=y_train):\n",
    "    \"\"\"\n",
    "    For now, we merge this function with LR_cost\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_vector:array-like\n",
    "        It can be train/validataion/train dataset, but should be matrix(m,n+1)\n",
    "        \n",
    "    y_vector:array_like\n",
    "        (m,NUM_LABELS)\n",
    "\n",
    "    \"\"\"\n",
    "    [m,n] = X_vector.shape\n",
    "    #because theta is include bias, so we still need add bias\n",
    "    X_bias = np.concatenate( (np.ones((m,1)),X_vector), axis=1 )\n",
    "    #X_bias=(m,NUM_FEATURE)=(15787, 10001), theta_his\n",
    "    y_hat = np.dot(X_bias, theta)\n",
    "    \n",
    "    #find the max of each example/row. we transfor all label into same format\n",
    "    pred = np.argmax(y_hat, axis=1)\n",
    "    ground_truth = np.argmax(y_vector, axis = 1)\n",
    "    \n",
    "    #if pred and ground_truth have same result, sum them and divide by total number of example\n",
    "    accuracy = sum(pred == ground_truth)/(float(m))\n",
    "    \n",
    "    return y_hat, pred, ground_truth, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(X_vector, y_vector, theta):\n",
    "    \"\"\"\n",
    "    This function is used to output classfiy report. We use one of paramters in result to determine \n",
    "    using which dataset\n",
    "    \"\"\"\n",
    "    y_hat, pred, ground_truth, accuracy = predict(theta, X_vector=X_vector, y_vector=y_vector)\n",
    "    target_names = ['class 0', 'class 1', 'class 2']\n",
    "    report = classification_report(ground_truth, pred, target_names=target_names, output_dict=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_LR(X, y, theta):\n",
    "    \"\"\"\n",
    "    Manually split data into train and validataion, and each validation import to one combination of \n",
    "    lambda list.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    lambda_list = [0.01, 0.1, 0, 1]\n",
    "    report_list = []\n",
    "    random_index = np.random.randint(len(lambda_list))\n",
    "    #kf = KFold(n_splits=k_fold)\n",
    "    #KFold(n_splits=k_fold, random_state=None, shuffle=False)\n",
    "    for j in range(len(lambda_list)):\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \\\n",
    "                                                              random_state=np.random.randint(0,10000,1)[0])\n",
    "        X_batch_list, y_batch_list = mini_batch(X_valid, y_valid, batch_size =256)\n",
    "        J_history, theta_history, acc_history = mini_batch_GD(X_batch_list, y_batch_list, theta, \\\n",
    "                                                   lambda_t=0.1, \\\n",
    "                                                    lr=1e-3, decay_factor = 0.99, \\\n",
    "                                                    epochs=5, \\\n",
    "                                                   optimizer='mini_batch', epsilon = 1e-1)\n",
    "        report_new = report(X_valid, y_valid, theta_history[-1])\n",
    "        report_list.append(report_new['macro avg']['precision'])\n",
    "    #we get the best\n",
    "    best_lambda = report_list.index(max(report_list))    \n",
    "    print(f\"The {best_lambda}th lambda_list={lambda_list[best_lambda]} is better\")\n",
    "    return X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3th lambda_list=1 is better\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_valid, y_valid = cross_val_LR(X_train, y_train, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:07<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "#*********************mini_batch*******************************\n",
    "X_batch_list, y_batch_list = mini_batch(X_valid, y_valid, batch_size =8)\n",
    "J_history_valid, theta_history_valid, acc_history_valid = mini_batch_GD(X_batch_list, y_batch_list, theta, \\\n",
    "                                                   lambda_t=0.1, lr=1e-3, decay_factor = 0.99, \\\n",
    "                                                    epochs=30, optimizer='mini_batch', epsilon = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:59<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "X_batch_list, y_batch_list = mini_batch(X_train, y_train, batch_size =8)\n",
    "J_history_train, theta_history_train, acc_history_train = mini_batch_GD(X_batch_list, y_batch_list, theta, \\\n",
    "                                                   lr=1e-3, decay_factor = 0.99, \\\n",
    "                                                   lambda_t=0.1, epochs=30, \\\n",
    "                                                   optimizer='mini_batch', epsilon = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because every iteration is differnt, and we need to present them in a single plot, so we only extract \n",
    "#data point to dictionary\n",
    "index_2 = np.arange(0,7230,241)\n",
    "sublist_2 = [J_history_valid[i] for i in index_2]\n",
    "\n",
    "index_3 = np.arange(0,len(J_history_train), len(J_history_train)/30)\n",
    "sublist_3 = [J_history_train[i] for i in index_2]\n",
    "sublist_4 = [acc_history_train[i] for i in index_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot val_loss, train_loss, train_acc\n",
    "dic = ['val_loss', 'train_loss', 'train_acc']\n",
    "minibatch_dict = {dic[0]:sublist_2, dic[1]:sublist_3, dic[2]:sublist_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:30<00:00,  3.01s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:15<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#***************************SGD************************************************\n",
    "theta = theta_initial(X_valid)\n",
    "J_sgd_history_train, theta_sgd_history_train, acc_sgd_history_train= sgd_GD(X_train, y_train, theta, \\\n",
    "                                                   lr=1e-3, decay_factor = 0.99, \\\n",
    "                                                   lambda_t=0.01, epochs=30, epsilon = 1e-3)\n",
    "theta = theta_initial(X_valid)\n",
    "J_sgd_history_valid, theta_sgd_history_valid, acc_sgd_history_valid= sgd_GD(X_valid, y_valid, theta, \\\n",
    "                                                   lr=1e-2, decay_factor = 0.99, \\\n",
    "                                                   lambda_t=0.01, epochs=30, epsilon = 1e-3)\n",
    "\n",
    "\n",
    "sgd = {dic[0]:J_sgd_history_valid, dic[1]:J_sgd_history_train, dic[2]:acc_sgd_history_train,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_a\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 10000)]           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 10,306,819\n",
      "Trainable params: 10,306,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9630 samples, validate on 1926 samples\n",
      "Epoch 1/30\n",
      "9630/9630 [==============================] - 8s 881us/sample - loss: 0.2010 - accuracy: 0.9122 - val_loss: 0.0453 - val_accuracy: 0.9856\n",
      "Epoch 2/30\n",
      "9630/9630 [==============================] - 6s 644us/sample - loss: 0.0441 - accuracy: 0.9832 - val_loss: 0.0175 - val_accuracy: 0.9934\n",
      "Epoch 3/30\n",
      "9630/9630 [==============================] - 6s 643us/sample - loss: 0.0153 - accuracy: 0.9935 - val_loss: 0.0075 - val_accuracy: 0.9972\n",
      "Epoch 4/30\n",
      "9630/9630 [==============================] - 6s 642us/sample - loss: 0.0085 - accuracy: 0.9961 - val_loss: 0.0041 - val_accuracy: 0.9979\n",
      "Epoch 5/30\n",
      "9630/9630 [==============================] - 6s 650us/sample - loss: 0.0060 - accuracy: 0.9965 - val_loss: 0.0034 - val_accuracy: 0.9977\n",
      "Epoch 6/30\n",
      "9630/9630 [==============================] - 6s 649us/sample - loss: 0.0047 - accuracy: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9978\n",
      "Epoch 7/30\n",
      "9630/9630 [==============================] - 6s 648us/sample - loss: 0.0048 - accuracy: 0.9968 - val_loss: 0.0029 - val_accuracy: 0.9981\n",
      "Epoch 8/30\n",
      "9630/9630 [==============================] - 6s 655us/sample - loss: 0.0044 - accuracy: 0.9973 - val_loss: 0.0045 - val_accuracy: 0.9983\n",
      "Epoch 9/30\n",
      "9630/9630 [==============================] - 6s 641us/sample - loss: 0.0046 - accuracy: 0.9967 - val_loss: 0.0028 - val_accuracy: 0.9984\n",
      "Epoch 10/30\n",
      "9630/9630 [==============================] - 6s 642us/sample - loss: 0.0042 - accuracy: 0.9966 - val_loss: 0.0029 - val_accuracy: 0.9981\n",
      "Epoch 11/30\n",
      "9630/9630 [==============================] - 6s 658us/sample - loss: 0.0042 - accuracy: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9984\n",
      "Epoch 12/30\n",
      "9630/9630 [==============================] - 6s 664us/sample - loss: 0.0039 - accuracy: 0.9973 - val_loss: 0.0024 - val_accuracy: 0.9984\n",
      "Epoch 13/30\n",
      "9630/9630 [==============================] - 6s 639us/sample - loss: 0.0043 - accuracy: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9984\n",
      "Epoch 14/30\n",
      "9630/9630 [==============================] - 6s 647us/sample - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9983\n",
      "Epoch 15/30\n",
      "9630/9630 [==============================] - 6s 655us/sample - loss: 0.0040 - accuracy: 0.9975 - val_loss: 0.0027 - val_accuracy: 0.9984\n",
      "Epoch 16/30\n",
      "9630/9630 [==============================] - 6s 652us/sample - loss: 0.0039 - accuracy: 0.9975 - val_loss: 0.0027 - val_accuracy: 0.9983\n",
      "Epoch 17/30\n",
      "9630/9630 [==============================] - 6s 653us/sample - loss: 0.0038 - accuracy: 0.9975 - val_loss: 0.0026 - val_accuracy: 0.9983\n",
      "Epoch 18/30\n",
      "9630/9630 [==============================] - 6s 654us/sample - loss: 0.0039 - accuracy: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9984\n",
      "Epoch 19/30\n",
      "9630/9630 [==============================] - 6s 652us/sample - loss: 0.0039 - accuracy: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9983\n",
      "Epoch 20/30\n",
      "9630/9630 [==============================] - 6s 652us/sample - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.0027 - val_accuracy: 0.9979\n",
      "Epoch 21/30\n",
      "9630/9630 [==============================] - 6s 649us/sample - loss: 0.0039 - accuracy: 0.9975 - val_loss: 0.0025 - val_accuracy: 0.9984\n",
      "Epoch 22/30\n",
      "9630/9630 [==============================] - 6s 644us/sample - loss: 0.0050 - accuracy: 0.9975 - val_loss: 0.0030 - val_accuracy: 0.9981\n",
      "Epoch 23/30\n",
      "9630/9630 [==============================] - 6s 645us/sample - loss: 0.0042 - accuracy: 0.9975 - val_loss: 0.0026 - val_accuracy: 0.9983\n",
      "Epoch 24/30\n",
      "9630/9630 [==============================] - 6s 648us/sample - loss: 0.0039 - accuracy: 0.9973 - val_loss: 0.0026 - val_accuracy: 0.9979\n",
      "Epoch 25/30\n",
      "9630/9630 [==============================] - 6s 661us/sample - loss: 0.0036 - accuracy: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9979\n",
      "Epoch 26/30\n",
      "9630/9630 [==============================] - 6s 648us/sample - loss: 0.0040 - accuracy: 0.9975 - val_loss: 0.0025 - val_accuracy: 0.9986\n",
      "Epoch 27/30\n",
      "9630/9630 [==============================] - 6s 648us/sample - loss: 0.0036 - accuracy: 0.9974 - val_loss: 0.0027 - val_accuracy: 0.9981\n",
      "Epoch 28/30\n",
      "9630/9630 [==============================] - 6s 642us/sample - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.0080 - val_accuracy: 0.9965\n",
      "Epoch 29/30\n",
      "9630/9630 [==============================] - 6s 651us/sample - loss: 0.0175 - accuracy: 0.9935 - val_loss: 0.0058 - val_accuracy: 0.9972\n",
      "Epoch 30/30\n",
      "9630/9630 [==============================] - 6s 652us/sample - loss: 0.0081 - accuracy: 0.9960 - val_loss: 0.0030 - val_accuracy: 0.9981\n"
     ]
    }
   ],
   "source": [
    "#*********************************Neural NetWork********************************************\n",
    "history = NN(X_train, y_train, X_valid, y_valid)\n",
    "NN_history = {dic[0]:history.history['val_loss'], \\\n",
    "              dic[1]:history.history['loss'], \\\n",
    "              dic[2]:history.history['accuracy']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9.Plot\"></a>\n",
    "# 9.Plot\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because matrix will occupy a lot of memory, so we need to delete them and release memory\n",
    "# %reset array\n",
    "# %xdel theta_history_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [02:45<00:00,  3.31s/it]\n"
     ]
    }
   ],
   "source": [
    "#*****************mini-batch loss plot****************************\n",
    "# X_batch_list, y_batch_list = mini_batch(X_train, y_train, batch_size =8)\n",
    "# J_history_train, theta_history_train, acc_history_train = mini_batch_GD(X_batch_list, y_batch_list, theta, \\\n",
    "#                                                    lr=1e-3, decay_factor = 0.99, \\\n",
    "#                                                    lambda_t=0.1, epochs=50, \\\n",
    "#                                                    optimizer='mini_batch', epsilon = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(J_history_train)), J_history_train)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Mini-batch Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %xdel theta_history_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:34<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "theta = theta_initial(X_train)\n",
    "J_sgd_history_train, theta_sgd_history_train, acc_sgd_history_train= sgd_GD(X_train, y_train, theta, \\\n",
    "                                                   lr=0.008, decay_factor = 0.99, \\\n",
    "                                                   lambda_t=0.1, epochs=100, epsilon = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(J_sgd_history_train)), J_sgd_history_train)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('SGD Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot():\n",
    "\n",
    "# #plot val_loss, train_loss, train_acc\n",
    "# dic = ['val_loss', 'train_loss', 'train_acc']\n",
    "\n",
    "# #each model build one dictionary\n",
    "# X_valid, y_valid = cross_val(X_vector_train, y_vector_train, theta)\n",
    "# X_batch_list, y_batch_list = mini_batch(X_valid, y_valid, batch_size =8)\n",
    "# J_history_valid, theta_history_valid, acc_history_valid = mini_batch_GD(X_batch_list, y_batch_list, theta, \\\n",
    "#                                                    lambda_t=0.1,X_train=X_train, y_train=y_train, \\\n",
    "#                                                     lr=1e-3, decay_factor = 0.99, \\\n",
    "#                                                     epochs=30, \\\n",
    "#                                                    optimizer='mini_batch', epsilon = 1e-1)\n",
    "\n",
    "# X_batch_list, y_batch_list = mini_batch(X_vector_train, y_vector_train, batch_size =8)\n",
    "# J_history_train, theta_history_train, acc_history_train = mini_batch_GD(X_batch_list, y_batch_list, theta, \\\n",
    "#                                                    lr=1e-3, decay_factor = 0.99, \\\n",
    "#                                                    lambda_t=0.1, epochs=30, \\\n",
    "#                                                    optimizer='mini_batch', epsilon = 1e-1)\n",
    "\n",
    "# #y_hat, pred, accuracy = predict(X_vector_train, y_vector_train,theta_history_train)\n",
    "# mini_batch = {dic[0]:J_history_valid, dic[1]:J_history_train, dic[2]:acc_history_train,}\n",
    "# for i in range(len(dic)):\n",
    "\n",
    "#     print(\"*\"*50)\n",
    "#     x_index = list(range(0,30))\n",
    "#     plt.plot(x_index, mini_batch[dic[i]], color = 'g', lw = 2, label = 'mini_batch '+str(dic[i]))\n",
    "#     print(\"*\"*50)\n",
    "\n",
    "\n",
    "# # J_history, grad_history, theta_history = sgd_GD(X_vector_train, y_vector_train, theta, \\\n",
    "# #                                                    lr=1e-3, decay_factor = 0.99, \\\n",
    "# #                                                    lambda_t=0.1, epochs=30, epsilon = 1e-3)\n",
    "\n",
    "\n",
    "\n",
    "# # sgd = {dic[0]:J_history_valid, dic[1]:J_history_train, dic[2]:acc_history_train,}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10.Compare Conclusion\"></a>\n",
    "# 10.Compare Conclusion\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we don't use binomial in Logistic Regression, we only can get a line as our boundary, which is not perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>We use two classifers, one is Logistic Regression and another is Neural Network. The big difference between these is Decsion Boundary. Decision boundary of LR is linear function, even in high dimension space, it is still a straight line. But decision boundary of Neural Network can fit non-linear classify task. So in this aspect, using LR in NLP task maybe not a good choice</li>\n",
    "    <li>In NLP task, cleaning data occupy a dominated posion. Garbage in garbage out. If we didn't use a better cleaning algorithm, you will get good accuracy/performance even you use great model to fit. For this task, I believe I still have imporvement aspect and that is also a important reason i did't get beautiful plot.</li>\n",
    "    <ul>\n",
    "        <li>Using stemming and lemmatization for raw corpus. That is standard step for NLP task</li>\n",
    "        <li>At present, I apply a rule which contain length of examples between 80% length and 20% length. This is only a mild stragegy. Within this strategy, I deleted too many valueable corpus. Drop raw corpus is not a good rule. Maybe droping raw corpus example by important and frequency is a good choice</li>\n",
    "        <li>TFIDF is default choice. Maybe i can try embedding</li>\n",
    "    </ul>\n",
    "    <li>In cross-validation part, 5-flod cross-validation should be a good point, but I only use my own code to evluate one single paramaters</li>\n",
    "    <li>Mini-batch is a more effective gradient descent algorithm compare to valina gradient descent. Especailly in NLP high dimension task, mini-batch will decreae runing time and increase convergence speed. But mini-bathc have its own difficult part.</li>\n",
    "    <ul>\n",
    "        <li>You have too decide your appropriate batch size acoording to corpus data type and your computer hardware configuration.</li>\n",
    "        <li>Once you change batch size a little bit, you have too change other parameters correspondingly. If you don't change other parameters, like learning rate and lambda, you loss might not convergence</li>\n",
    "    </ul>\n",
    "    <li>Stochastic gradient descent is a more cost cheap choice. It will only import one example and will accelerate descent process.Most of important, I think in this NLP task, SGD is more appropriate than mini-batch. Because our corpus is one example one paragraph. If we use mini-batch shuffle every example, we will get a less meaning relationship combination, although they belong to a single Author. But SGD can matain a meaningful exmaple and train model with it.</li>\n",
    "    <li>But the real problem of accuracy and performance is epochs number or laptop computation. You can see loss decrease from plot but not significant. If i have more powerful server, i can iterate 10 thousand times to get a small loss</li>\n",
    "    <li>From this aspect, Neural network is good choice. NN use costless calculation to get a more valid result.</li>\n",
    "    <li>There are a lot of aspect and algorithm i can apply. I record them in next chapter</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Need Improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>stemming and lemming</li>\n",
    "    <li>shuffle corpus order</li>\n",
    "    <li>plot length of sentence, eliminate that too long, and set MAX_LEN in a reasonable range</li>\n",
    "    <li>import too much parameter for some complex function and need to build a GLOBAL hyperparamters system</li>\n",
    "    <li>provide lr for every paramter, and momentoumn</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Don't use code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_data():\\n    file_path = \"03_data/11_Project Gutenberg Data/28054-0.txt\"\\n    \\n    f = open(file_path, \\'r\\')\\n    print(f.read())\\n\\nDIRECTORY_PATH = \\'03_data/11_Project Gutenberg Data/\\'\\nFILE_NAMES = [\\'28054-0.txt\\', \\'pg1661.txt\\', \\'pg31100.txt\\']\\n\\nfor name in FILE_NAMES:\\n    text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_PATH+name)\\nparent_dir = os.path.dirname(text_dir)\\n\\ndef labeler(example, index):\\n    return example, tf.cast(index, tf.int64)  \\n\\nlabeled_data_sets = []\\n\\nfor i, file_name in enumerate(FILE_NAMES):\\n    lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\\n    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\\n    labeled_data_sets.append(labeled_dataset)\\n\\n\\n\\nimport scipy.sparse\\ndef oneHotIt(Y):\\n    m = Y.shape[0]\\n    #Y = Y[:,0]\\n    OHX = scipy.sparse.csr_matrix((np.ones(m), (Y, np.array(range(m)))))\\n    OHX = np.array(OHX.todense()).T\\n    return OHX\\n\\nimport utils\\n\\n\\n\\n\\n x=[\\'a\\' , \\'b\\']\\n\\nx.extend([\\'5\\',  \\'6\\']),\\n\\nx\\n\\nlen(x)\\n\\nx =[0, 1, 2, 3, 4, 5, 6]\\n\\nx[-3]\\n\\nimport numpy as np\\n\\nx=np.random.random((3,4))\\n\\ny = np.random.random((3,1))\\n\\nx+y\\n\\nx = np.random.random((3, 4))\\n\\nfor i in range(100,1000):\\n    for j in range(x.shape[1]):\\n        x[i,j] += 5\\n\\nx[np.arange(100,1000), :] +=5\\n\\ndef test_fun(a=None):\\n    print(a)\\n\\ntest_fun(a=8)\\n\\nvector_1.shape\\n\\nvector_2 = np.random.randn(3,5)\\nvector_2\\n\\nnp.random.shuffle(vector_2)\\n\\nvector_2\\n\\narr = np.arange(12).reshape(3,4)\\n\\narr\\n\\nnp.random.shuffle(arr)\\narr\\n\\n\\n\\n#     for train_index, valid_index in kf.split(X):\\n#         print(\"TRAIN:\", len(train_index), \"VALID:\", len(valid_index))\\n#         X_train, X_valid = X[train_index,:], X[valid_index,:]\\n#         y_train, y_valid = y[train_index,:], y[valid_index,:]\\n#         J_history, grad_history, theta_history = mini_batch_GD(X_valid, y_valid, lambda_t = lambda_list[i])\\n#         i = i + 1\\n#         report = report(X_valid, y_valid)\\n#         report_list.append()\\n\\n\\n\\n\\n# This part is used for verify processing result\\n# #this will show which vector was transfromed back to words. We use this output to compare with corpus[0]\\n\\n# vect.inverse_transform(data_4)[0]\\n# corpus[0]\\n\\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    file_path = \"03_data/11_Project Gutenberg Data/28054-0.txt\"\n",
    "    \n",
    "    f = open(file_path, 'r')\n",
    "    print(f.read())\n",
    "\n",
    "DIRECTORY_PATH = '03_data/11_Project Gutenberg Data/'\n",
    "FILE_NAMES = ['28054-0.txt', 'pg1661.txt', 'pg31100.txt']\n",
    "\n",
    "for name in FILE_NAMES:\n",
    "    text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_PATH+name)\n",
    "parent_dir = os.path.dirname(text_dir)\n",
    "\n",
    "def labeler(example, index):\n",
    "    return example, tf.cast(index, tf.int64)  \n",
    "\n",
    "labeled_data_sets = []\n",
    "\n",
    "for i, file_name in enumerate(FILE_NAMES):\n",
    "    lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\n",
    "    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
    "    labeled_data_sets.append(labeled_dataset)\n",
    "\n",
    "\n",
    "\n",
    "import scipy.sparse\n",
    "def oneHotIt(Y):\n",
    "    m = Y.shape[0]\n",
    "    #Y = Y[:,0]\n",
    "    OHX = scipy.sparse.csr_matrix((np.ones(m), (Y, np.array(range(m)))))\n",
    "    OHX = np.array(OHX.todense()).T\n",
    "    return OHX\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " x=['a' , 'b']\n",
    "\n",
    "x.extend(['5',  '6']),\n",
    "\n",
    "x\n",
    "\n",
    "len(x)\n",
    "\n",
    "x =[0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "x[-3]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x=np.random.random((3,4))\n",
    "\n",
    "y = np.random.random((3,1))\n",
    "\n",
    "x+y\n",
    "\n",
    "x = np.random.random((3, 4))\n",
    "\n",
    "for i in range(100,1000):\n",
    "    for j in range(x.shape[1]):\n",
    "        x[i,j] += 5\n",
    "\n",
    "x[np.arange(100,1000), :] +=5\n",
    "\n",
    "def test_fun(a=None):\n",
    "    print(a)\n",
    "\n",
    "test_fun(a=8)\n",
    "\n",
    "vector_1.shape\n",
    "\n",
    "vector_2 = np.random.randn(3,5)\n",
    "vector_2\n",
    "\n",
    "np.random.shuffle(vector_2)\n",
    "\n",
    "vector_2\n",
    "\n",
    "arr = np.arange(12).reshape(3,4)\n",
    "\n",
    "arr\n",
    "\n",
    "np.random.shuffle(arr)\n",
    "arr\n",
    "\n",
    "\n",
    "\n",
    "#     for train_index, valid_index in kf.split(X):\n",
    "#         print(\"TRAIN:\", len(train_index), \"VALID:\", len(valid_index))\n",
    "#         X_train, X_valid = X[train_index,:], X[valid_index,:]\n",
    "#         y_train, y_valid = y[train_index,:], y[valid_index,:]\n",
    "#         J_history, grad_history, theta_history = mini_batch_GD(X_valid, y_valid, lambda_t = lambda_list[i])\n",
    "#         i = i + 1\n",
    "#         report = report(X_valid, y_valid)\n",
    "#         report_list.append()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This part is used for verify processing result\n",
    "# #this will show which vector was transfromed back to words. We use this output to compare with corpus[0]\n",
    "\n",
    "# vect.inverse_transform(data_4)[0]\n",
    "# corpus[0]\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef token(dataset):\\n\\n#     For now, we didn\\'t use this function\\n#     Parameters:\\n#     -----------\\n#     dataset:list\\n#         Contain all raw data, we need use tokenizer to preprocess data\\n    \\n#     Return:\\n#     -------\\n#     tokenizer:tensorflow config\\n\\n    #remove punctuation and irrelvant symbols\\n    #we use fillter to remove punctuation\\n    vocab_size = 100000\\n    max_length = 100\\n    \\n    tokenizer = Tokenizer(num_words=vocab_size,                           oov_token=\"<OOV>\",                           filters=\\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r”\\', \\n                          lower=True\\n                         )\\n    #dataset_1 = tokenizer.get_config()\\n\\n    #transfor sentence to number vector\\n    a = tokenizer.fit_on_texts(dataset)\\n    \\n    \\n        \\n    #get the index of each indivudule word\\n    word_index = tokenizer.word_index\\n    \\n    #only choose most frequency 10,000 word_index and transfrom sentences with them into number vector \\n    #like[564, 452, 23, 1]\\n    #the out of vocabulary wiht be give 1. \\n    #Maximize number of texts_to_sequences() will be 9999, which means the 10000th frequceny will \\n    #not show in this sequcen\\n    sequences = tokenizer.texts_to_sequences(dataset)\\n    \\n    #maintain the sentence into same length\\n    #padded = pad_sequences(sequences)\\n    #If you want zero at the end, using padding=\\'post\\'\\n    padded = pad_sequences(sequences, padding=\\'post\\', maxlen=max_length, truncating=\\'post\\')\\n\\n    \\n    return tokenizer, word_index, sequences, padded\\n\\n#tokenizer, word_index, sequences, padded = token(data_1)\\n\\n\\n\\nlen(corpus_train[8])\\n\\nlength_list=[]\\nlength_corpus = len(corpus_6)\\nlength_arr = np.zeros(length_corpus)\\nfor i in range(0, length_corpus):\\n    #print(i)\\n    try:\\n        length_arr[i]=(len(corpus_6[i]))\\n    except:\\n        length_arr[i]=0\\narray_2 = np.arange(length_corpus) \\nplt.plot(array_2, length_arr)\\n\\ncorpus_9[\\'AUTHOR\\']\\n\\nlength_arr = np.zeros(length_corpus)\\nfor i in range(0, length_corpus):\\n    #print(i)\\n    try:\\n        length_arr[i]=(len(corpus_9.iloc[i,0]))\\n    except:\\n        length_arr[i]=0\\nlength_corpus = len(corpus_9)\\narray_3 = np.arange(length_corpus) \\nplt.plot(array_3, length_arr)\\n\\nplt.plot(array_3, np.sort(length_arr))\\n\\nlength_corpus = len(corpus_9)\\n\\nlength_corpus\\n\\nplt.plot(array_2, np.sort(length_arr))\\n\\ncorpus_8[\\'AUTHOR\\']\\n\\nfrom scipy import stats\\nstats.describe(corpus_8[\\'AUTHOR\\'])\\n\\nlen(length_arr)\\n\\nlen(length_arr[length_arr>600])\\n\\nlen(length_arr[length_arr<60])\\n\\nlen(length_arr[length_arr==0])\\n\\nlen(corpus_train[1235])\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#This is another token way\n",
    "\"\"\"\n",
    "def token(dataset):\n",
    "\n",
    "#     For now, we didn't use this function\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     dataset:list\n",
    "#         Contain all raw data, we need use tokenizer to preprocess data\n",
    "    \n",
    "#     Return:\n",
    "#     -------\n",
    "#     tokenizer:tensorflow config\n",
    "\n",
    "    #remove punctuation and irrelvant symbols\n",
    "    #we use fillter to remove punctuation\n",
    "    vocab_size = 100000\n",
    "    max_length = 100\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=vocab_size, \\\n",
    "                          oov_token=\"<OOV>\", \\\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r”', \n",
    "                          lower=True\n",
    "                         )\n",
    "    #dataset_1 = tokenizer.get_config()\n",
    "\n",
    "    #transfor sentence to number vector\n",
    "    a = tokenizer.fit_on_texts(dataset)\n",
    "    \n",
    "    \n",
    "        \n",
    "    #get the index of each indivudule word\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    #only choose most frequency 10,000 word_index and transfrom sentences with them into number vector \n",
    "    #like[564, 452, 23, 1]\n",
    "    #the out of vocabulary wiht be give 1. \n",
    "    #Maximize number of texts_to_sequences() will be 9999, which means the 10000th frequceny will \n",
    "    #not show in this sequcen\n",
    "    sequences = tokenizer.texts_to_sequences(dataset)\n",
    "    \n",
    "    #maintain the sentence into same length\n",
    "    #padded = pad_sequences(sequences)\n",
    "    #If you want zero at the end, using padding='post'\n",
    "    padded = pad_sequences(sequences, padding='post', maxlen=max_length, truncating='post')\n",
    "\n",
    "    \n",
    "    return tokenizer, word_index, sequences, padded\n",
    "\n",
    "#tokenizer, word_index, sequences, padded = token(data_1)\n",
    "\n",
    "\n",
    "\n",
    "len(corpus_train[8])\n",
    "\n",
    "length_list=[]\n",
    "length_corpus = len(corpus_6)\n",
    "length_arr = np.zeros(length_corpus)\n",
    "for i in range(0, length_corpus):\n",
    "    #print(i)\n",
    "    try:\n",
    "        length_arr[i]=(len(corpus_6[i]))\n",
    "    except:\n",
    "        length_arr[i]=0\n",
    "array_2 = np.arange(length_corpus) \n",
    "plt.plot(array_2, length_arr)\n",
    "\n",
    "corpus_9['AUTHOR']\n",
    "\n",
    "length_arr = np.zeros(length_corpus)\n",
    "for i in range(0, length_corpus):\n",
    "    #print(i)\n",
    "    try:\n",
    "        length_arr[i]=(len(corpus_9.iloc[i,0]))\n",
    "    except:\n",
    "        length_arr[i]=0\n",
    "length_corpus = len(corpus_9)\n",
    "array_3 = np.arange(length_corpus) \n",
    "plt.plot(array_3, length_arr)\n",
    "\n",
    "plt.plot(array_3, np.sort(length_arr))\n",
    "\n",
    "length_corpus = len(corpus_9)\n",
    "\n",
    "length_corpus\n",
    "\n",
    "plt.plot(array_2, np.sort(length_arr))\n",
    "\n",
    "corpus_8['AUTHOR']\n",
    "\n",
    "from scipy import stats\n",
    "stats.describe(corpus_8['AUTHOR'])\n",
    "\n",
    "len(length_arr)\n",
    "\n",
    "len(length_arr[length_arr>600])\n",
    "\n",
    "len(length_arr[length_arr<60])\n",
    "\n",
    "len(length_arr[length_arr==0])\n",
    "\n",
    "len(corpus_train[1235])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
