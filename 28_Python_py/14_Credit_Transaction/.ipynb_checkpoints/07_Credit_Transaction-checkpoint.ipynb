{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <a id=\"1.Summary\">1.Summary</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"2.Table of Contents\">2.Table of Contents</a>\n",
    "<a href=\"#1.Summary\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><a href=\"#1.Summary\">Summary</a></li>\n",
    "    <li><a href=\"#2.Table of Contents\">Table of Contents</a></li>\n",
    "    <li><a href=\"#3.Code Part\">Code Part</a></li>\n",
    "    <ul>\n",
    "       <li><a href=\"#3.1 Credit Transaction data\">3.1 Credit Transaction data</a></li>\n",
    "       <li><a href=\"#3.2 Energy Pandas\">3.2 Energy Pandas</a></li> \n",
    "       <li><a href=\"#3.3 Main Function\">3.3 Main Function</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#4.Credit Transaction Question\">Credit Transaction Question</a></li>\n",
    "    <ul>\n",
    "       <li><a href=\"#total amount\">4.1 What is total amount spending captured in this dataset?</a></li>\n",
    "       <li><a href=\"#4.2 How much was spend at WW GRAINGER?\">4.2 How much was spend at WW GRAINGER?</a></li> \n",
    "       <li><a href=\"#4.3 How much was spend at WM SUPERCENTER?\">4.3 How much was spend at WM SUPERCENTER?</a></li>\n",
    "       <li><a href=\"#4.4 How much was spend at GROCERY STORES?\">4.4 How much was spend at GROCERY STORES?</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#5.Energy Pandas Question\">Energy Pandas Question</a></li>\n",
    "    <li><a href=\"#6.Test Code\">Test Code</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"3.Code Part\">3.Code Part</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"3.1 Credit Transaction data\">3.1 Credit Transaction data</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class EdaData(object):\n",
    "    \"\"\"\n",
    "    Try to use this class to answer first task\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def eda_data(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # read data\n",
    "        self.df = pd.read_csv(\"03_data/res_purchase_2014.csv\", low_memory=False)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def convert_float(self, x):\n",
    "        \"\"\"\n",
    "        Input is each individual element\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if x[0] == '(' and x[-1] == ')':\n",
    "            x_new = re.findall(\"\\d*\\.?\\d+\", x)\n",
    "            return -float(x_new[0])\n",
    "        else:\n",
    "            # we can ignore there type, just treate them as str and extract them\n",
    "            x_new = re.findall(\"\\d*\\.?\\d+\", x)\n",
    "            # transform to float\n",
    "            return float(x_new[0])\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"\n",
    "        When we observe, we see ($29.99) to represent negative\n",
    "        And there are some number have word, like zero, in this column\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # we need clean this column data to float\n",
    "        # apply() input is each element\n",
    "        self.df['Cleaned_Amount'] = self.df['Amount'].apply(self.convert_float)\n",
    "        return self.df\n",
    "\n",
    "\n",
    "        # *************NOT EFFICIENT WAY****************************\n",
    "        # there are various data type and differnt context in ['amount'] column\n",
    "        # we need clean data before analysis\n",
    "        # for idx, i in tqdm(enumerate(amount_series)):\n",
    "        #     # first data are float type\n",
    "        #     if isinstance(i, float):\n",
    "        #         #         print(i)\n",
    "        #         pass\n",
    "        #     # we filter data from minority\n",
    "        #     elif i[0] == '(' and i[-1] == ')':\n",
    "        #         #         print(i)\n",
    "        #         # this is specify for data($29,99)\n",
    "        #         i_new = i.replace('(', '')\n",
    "        #         i_new = i_new.replace(')', '')\n",
    "        #         # replace $ with - and transform to float\n",
    "        #         i_new = float(i_new.replace('$', '-'))\n",
    "        #         #         print(i_new, type(i_new))\n",
    "        #         # replace dataframe with new clean data\n",
    "        #         self.df.iloc[idx, 6] = i_new\n",
    "        #     elif type(i) == str:\n",
    "        #         # use regex to extract float format numerical data\n",
    "        #         #         print(idx, type(i), i)\n",
    "        #         i_new = re.findall('\\d*\\.?\\d+', i)\n",
    "        #         self.df.iloc[idx, 6] = float(i_new[0])\n",
    "        #     elif type(i) == int:\n",
    "        #         #         pass\n",
    "        #         # transform int to float\n",
    "        #         self.df.iloc[idx, 6] = float(i)\n",
    "        #     #         print(i)\n",
    "        #     # if former filter cannot process some data then print these unprocessed data\n",
    "        #     else:\n",
    "        #         print(idx, type(i))\n",
    "\n",
    "        # save to clean csv\n",
    "        # self.df.to_csv(\"03_data/cleaned_purchase_2014.csv\")\n",
    "        #\n",
    "        # return self.df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"3.2 Energy Pandas\">3.2 Energy Pandas</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class Energy(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def import_data(self):\n",
    "        \"\"\"\n",
    "        ONLY for read data\n",
    "        \"\"\"\n",
    "        self.balance_sheet_df = pd.read_excel('03_data/Energy.xlsx')\n",
    "        self.rating_df = pd.read_excel('03_data/EnergyRating.xlsx')\n",
    "        print(\"*\"*30,\"5.1 Read ’Energy.xlsx’ and ’EnergyRating.xlsx’\",\"*\"*30)\n",
    "        print(f\"Energy.xlsx is a {self.balance_sheet_df.shape} BalanceSheet\")\n",
    "        print(f\"EnergyRating.xlsx is a {self.rating_df.shape} Ratings\")\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n'*3)\n",
    "        return self.balance_sheet_df, self.rating_df\n",
    "\n",
    "    def clean_data(self, df):\n",
    "        \"\"\"\n",
    "        we need import t\n",
    "        Arugs:\n",
    "        ----\n",
    "        df:DataFrame\n",
    "            should be balance_sheet_df and rating_df\n",
    "        Return:\n",
    "        ------\n",
    "        df:DataFrame\n",
    "            cleaned DataFrame after drop and fillna with mean\n",
    "        \"\"\"\n",
    "        # if we find 90% percential is zero or nan, then we think more than 90% value\n",
    "        # in this column is 0 or missing value\n",
    "        quantile_9_series = df.quantile(q=0.9, axis=0)\n",
    "        # initial drop column list\n",
    "        drop_list = []\n",
    "        # these two list is not used yet\n",
    "        suspicion_list = []\n",
    "        remain_list = []\n",
    "        # if we find its 90% quantile is still zero or np.nan, then we drop this how column\n",
    "        for index, value in quantile_9_series.items():\n",
    "            # if this column have 90% zero or np.nan value, we add this column name into drop list\n",
    "            if value == 0 or value == np.nan:\n",
    "                # print(index, value)\n",
    "                drop_list.append(index)\n",
    "            # except use value to judge, we also can use df.isna() and df.isnull() to help\n",
    "            elif df[index].isna().all() or df[index].isnull().all():\n",
    "                # print(\"*\" * 20, index, value, \"*\" * 20, end='\\n')\n",
    "                drop_list.append(index)\n",
    "            # if we find its 90% is less than 10, we add it into suspicious list\n",
    "            elif value < 10:\n",
    "                # print(\"*\" * 20, index, value, \"*\" * 20, end='\\n')\n",
    "                suspicion_list.append(index)\n",
    "            else:\n",
    "                remain_list.append(index)\n",
    "        # then we drop these column\n",
    "        df = df.drop(columns=drop_list)\n",
    "        print(\"*\"*30,\"5.2 Drop the column if more than 90% value in this colnmn is 0’\",\"*\"*30)\n",
    "        print(f\"Total {len(drop_list)} columns has been dropped\")\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n'*3)\n",
    "\n",
    "        # print(f\"In {df.__name__}\")\n",
    "        # before cleaned, the True/False for nan value\n",
    "        print(\"*\" * 30, \"5.3 Replace all None or NaN with average value of each column’\", \"*\" * 30)\n",
    "        print(f\"Before fill nan, \\n\"\n",
    "              f\"we have {df.isnull().any().value_counts()[0]} columns don't contain np.nan value,\\n\"\n",
    "              f\"we have {df.isnull().any().value_counts()[1]} columns contain np.nan value\",end='\\n')\n",
    "        # we use current column mean value to fill nan value in DataFrame\n",
    "        # df.mean(axis=0) will provide column mean for each column\n",
    "        df = df.fillna(df.mean(axis = 0))\n",
    "        # after cleaned, the True/False for nan value\n",
    "        print(f\"After fill nan, \\n\"\n",
    "              f\"we have {df.isnull().any().value_counts()[0]} columns don't have np.nan value\",end='\\n')\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n'*3)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def normalize(self, df, exclude_list):\n",
    "        \"\"\"\n",
    "        Two step, first is identify which column is nurmical, second is normalize these columns\n",
    "        because we only process balance_sheet_df, so this function is only fit this DataFrame\n",
    "        Argus:\n",
    "        -----\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            normalized DataFrame with MinMax() method\n",
    "        \"\"\"\n",
    "        print(\"*\" * 30, \"5.4 Normalize the table\", \"*\" * 30)\n",
    "        start_time = time.time()\n",
    "        # initial columns value dtype pands.Series\n",
    "        col_dtype_series = df.dtypes\n",
    "        # initial the remain column list\n",
    "        numerical_list = []\n",
    "        object_list = []\n",
    "        # we use items() to begin our iteration process\n",
    "        for index, value in col_dtype_series.items():\n",
    "            # typically we only have three dtype: int64, float64 and object\n",
    "            if value == 'int64' or value == 'float64':\n",
    "                # restore these columns names (value) in numerical_list\n",
    "                numerical_list.append(index)\n",
    "            else:\n",
    "                # maybe create a dictionary to restore index(column name) and value(dtype) is better\n",
    "                object_list.append(index)\n",
    "\n",
    "        # next step we need only reserve the column should be normialization\n",
    "        # Date, year, month and company number should not be include\n",
    "        # for column names, should be in numerical_list but not in exculde_list\n",
    "        normalize_list = [item for item in numerical_list if item not in exclude_list]\n",
    "\n",
    "        # use apply() + function() to complete normalization\n",
    "        # apply need act on a DataFrame, not a pandas.Series, which means df[normalize_list] actually return\n",
    "        # a DataFrame to norm_df, not a single column/line\n",
    "        # all processing in lambda target function (min_max()) input is always a singal whole column\n",
    "        norm_df = df[normalize_list].apply(lambda x: self.min_max(x), axis= 0)\n",
    "        # three way for apply function, the result is same\n",
    "        # alone column direct to process min_max() function\n",
    "        # norm_df = df.apply(self.min_max, axis = 0)\n",
    "        # norm_df = df.apply(lambda x:(x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "        print(f\"There are {len(normalize_list)} columns are numerical by MinMax method.\")\n",
    "        cost_time = round((time.time() - start_time), 4)\n",
    "        print(\"*\" * 30, \"End normalize() with {} second\".format(cost_time), \"*\" * 30, '\\n'*3)\n",
    "\n",
    "        return norm_df\n",
    "\n",
    "    def min_max(self, series):\n",
    "        \"\"\"\n",
    "        We can directly use this function on DataFrame\n",
    "\n",
    "        :param series: input should be a column from dataframe and then we use MinMax() scalar for nomalization\n",
    "        :return: a normalized column\n",
    "        \"\"\"\n",
    "        return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "    def statistic_info(self, x):\n",
    "        \"\"\"\n",
    "        Argus:\n",
    "        ------\n",
    "        x:pandas.Series\n",
    "            manipulate as whole column\n",
    "        \"\"\"\n",
    "\n",
    "        ser = pd.Series(\n",
    "            [x.count(), x.mean(), x.std(), x.min(), x.quantile(0.25), x.quantile(0.5), x.quantile(0.75), x.max()],\n",
    "            index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "\n",
    "        return ser\n",
    "\n",
    "    def display_desribe(self, cleaned_balance_df):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # mimic df.desribe()\n",
    "        # according to double-check, \"Assets Netting & Other Adjustments\" this column has been dropped in first step\n",
    "        # because most of values are zero\n",
    "        display_list = [\"Current Assets - Other - Total\",\n",
    "                        \"Current Assets - Total\",\n",
    "                        \"Other Long-term Assets\"]\n",
    "        display_df = cleaned_balance_df[display_list]\n",
    "        # pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "        print(\"*\" * 30, \"5.5 Simulate describe() function\", \"*\" * 30)\n",
    "        print(display_df.apply(self.statistic_info))\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n'*3)\n",
    "        print(\"*\" * 30, \"5.6 Calculate the correlation matrix\", \"*\" * 30)\n",
    "        print(display_df.corr)\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n'*3)\n",
    "\n",
    "    def postfix_extract(self, df):\n",
    "        \"\"\"\n",
    "        Only used for cleaned_balance_df\n",
    "        :param\n",
    "        :return: split string with ' ' whitespace, this will return a list and extract last one item\n",
    "        \"\"\"\n",
    "        # x:str will be every element in this column\n",
    "        print(\"*\" * 30, \"5.7 Extract Company Postfix\", \"*\" * 30)\n",
    "        df['CO'] = df['Company Name'].map(lambda x: x.split(' ')[-1])\n",
    "        df.groupby(['CO'])['CO'].count().plot(kind='bar')\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n' * 3)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def merge_df(self, df1, df2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param df1:\n",
    "        :param df2:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        merge_list = ['Data Date', 'Global Company Key']\n",
    "        print(\"*\" * 30, f\"5.8 Merge on {merge_list} with two DataFrame\", \"*\" * 30)\n",
    "        Matched = pd.merge(df1, df2, on=merge_list, how='inner')\n",
    "        print(f\"New Datase have {Matched.shape} size\")\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n' * 3)\n",
    "\n",
    "        return Matched\n",
    "\n",
    "    def rating_numerical(self, x):\n",
    "        \"\"\"\n",
    "        Transform alpha format to numerical format\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if x == 'AAA':\n",
    "            return 0\n",
    "        elif x == 'AA+':\n",
    "            return 1\n",
    "        elif x == 'AA':\n",
    "            return 2\n",
    "        elif x == 'AA-':\n",
    "            return 3\n",
    "        elif x == 'A+':\n",
    "            return 4\n",
    "        elif x == 'A':\n",
    "            return 5\n",
    "        elif x == 'A-':\n",
    "            return 6\n",
    "        elif x == 'BBB+':\n",
    "            return 7\n",
    "        elif x == 'BBB':\n",
    "            return 8\n",
    "        elif x == 'BBB-':\n",
    "            return 9\n",
    "        elif x == 'BB+':\n",
    "            return 10\n",
    "        elif x == 'BB':\n",
    "            return 11\n",
    "        else:\n",
    "            return 12\n",
    "\n",
    "    def rating_part(self, Matched):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        print(\"*\" * 30, f\"5.9 Transform Alpha Format to Numerical Format\", \"*\" * 30)\n",
    "        Matched['Rate'] = Matched['S&P Domestic Long Term Issuer Credit Rating'].map(self.rating_numerical)\n",
    "        Matched.groupby(['Rate'])['Rate'].count().plot(kind='bar')\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n' * 3)\n",
    "\n",
    "        print(\"*\" * 30, f\"5.10 Distribute Frequence\", \"*\" * 30)\n",
    "        Matched[Matched['CO'] == 'CO'].groupby(['S&P Domestic Long Term Issuer Credit Rating'])['Rate']\\\n",
    "            .count().plot(kind='bar')\n",
    "        print(\"*\" * 40, \"END\", \"*\" * 40, '\\n' * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"3.3 Main Function\">3.3 Main Function</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5.1 Read ’Energy.xlsx’ and ’EnergyRating.xlsx’ ******************************\n",
      "Energy.xlsx is a (844, 380) BalanceSheet\n",
      "EnergyRating.xlsx is a (2522, 7) Ratings\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.2 Drop the column if more than 90% value in this colnmn is 0’ ******************************\n",
      "Total 122 columns has been dropped\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.3 Replace all None or NaN with average value of each column’ ******************************\n",
      "Before fill nan, \n",
      "we have 19 columns don't contain np.nan value,\n",
      "we have 239 columns contain np.nan value\n",
      "After fill nan, \n",
      "we have 258 columns don't have np.nan value\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.2 Drop the column if more than 90% value in this colnmn is 0’ ******************************\n",
      "Total 1 columns has been dropped\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.3 Replace all None or NaN with average value of each column’ ******************************\n",
      "Before fill nan, \n",
      "we have 4 columns don't contain np.nan value,\n",
      "we have 2 columns contain np.nan value\n",
      "After fill nan, \n",
      "we have 4 columns don't have np.nan value\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.4 Normalize the table ******************************\n",
      "There are 241 columns are numerical by MinMax method.\n",
      "****************************** End normalize() with 0.1466 second ****************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.5 Simulate describe() function ******************************\n",
      "       Current Assets - Other - Total  Current Assets - Total  \\\n",
      "count                      844.000000              844.000000   \n",
      "mean                      1037.255108             9735.614198   \n",
      "std                       1578.836159            13568.222671   \n",
      "min                          2.671000              144.786000   \n",
      "25%                        181.500000             1499.018250   \n",
      "50%                        448.677000             4744.000000   \n",
      "75%                       1037.255108            11617.250000   \n",
      "max                       9476.000000            76160.000000   \n",
      "\n",
      "       Other Long-term Assets  \n",
      "count              844.000000  \n",
      "mean              1486.818614  \n",
      "std               2441.795091  \n",
      "min                 13.072000  \n",
      "25%                187.456000  \n",
      "50%                827.000000  \n",
      "75%               1492.000000  \n",
      "max              40233.000000  \n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.6 Calculate the correlation matrix ******************************\n",
      "<bound method DataFrame.corr of      Current Assets - Other - Total  Current Assets - Total  \\\n",
      "0                            1502.0                  8780.0   \n",
      "1                            1434.0                  8296.0   \n",
      "2                             865.0                  8839.0   \n",
      "3                            1002.0                  8780.0   \n",
      "4                             759.0                  9436.0   \n",
      "..                              ...                     ...   \n",
      "839                           183.0                  9471.0   \n",
      "840                           204.0                  8097.0   \n",
      "841                           142.0                 10304.0   \n",
      "842                           176.0                  9545.0   \n",
      "843                           236.0                 10401.0   \n",
      "\n",
      "     Other Long-term Assets  \n",
      "0                    2568.0  \n",
      "1                    2587.0  \n",
      "2                    2742.0  \n",
      "3                    2638.0  \n",
      "4                    2602.0  \n",
      "..                      ...  \n",
      "839                   119.0  \n",
      "840                   886.0  \n",
      "841                   875.0  \n",
      "842                   848.0  \n",
      "843                   107.0  \n",
      "\n",
      "[844 rows x 3 columns]>\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.7 Extract Company Postfix ******************************\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.8 Merge on ['Data Date', 'Global Company Key'] with two DataFrame ******************************\n",
      "New Datase have (822, 263) size\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.9 Transform Alpha Format to Numerical Format ******************************\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.10 Distribute Frequence ******************************\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# from class_31_eda import EdaData\n",
    "# from class_32_energy import Energy\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Beacause running cleaning process will wast a lot of time, so i directly read file from cleaned data\n",
    "    that i processed before\n",
    "    This function draw the whole procee of each step\n",
    "    :param object:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #*************Part One*******************\n",
    "    eda_class = EdaData()\n",
    "    credit_df = eda_class.eda_data()\n",
    "    cleaned_credit_df = eda_class.clean_data()\n",
    "    # cleaned_credit_df = pd.read_csv('03_data/cleaned_purchase_2014.csv')\n",
    "\n",
    "    #**********Part Two****************\n",
    "    energy_class = Energy()\n",
    "    balance_sheet_df, rating_df = energy_class.import_data()\n",
    "    # drop nan column, replace NaN value with mean\n",
    "    cleaned_balance_df = energy_class.clean_data(balance_sheet_df)\n",
    "    cleaned_rating_df = energy_class.clean_data(rating_df)\n",
    "\n",
    "    # normalize, becase rating_df only have data and company no is numerical, so we only process balacne_sheet\n",
    "    # we don't process these not calcuation nuermical column, like date, year, month, company number\n",
    "    # initial a exclude_list to deduct these columns from normalization queue\n",
    "    exclude_list = ['Global Company Key', 'Data Date', 'Fiscal Year', 'Fiscal Quarter', 'Fiscal Year-end Month']\n",
    "    norm_df = energy_class.normalize(cleaned_balance_df, exclude_list)\n",
    "\n",
    "    energy_class.display_desribe(cleaned_balance_df)\n",
    "\n",
    "    cleaned_balance_df = energy_class.postfix_extract(cleaned_balance_df)\n",
    "\n",
    "    Matched = energy_class.merge_df(cleaned_balance_df, cleaned_rating_df)\n",
    "\n",
    "    energy_class.rating_part(Matched)\n",
    "\n",
    "    return (cleaned_credit_df, balance_sheet_df, rating_df, cleaned_balance_df, cleaned_rating_df,\n",
    "            norm_df, Matched)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    (cleaned_credit_df, balance_sheet_df, rating_df, cleaned_balance_df, cleaned_rating_df,\n",
    "     norm_df, Matched)  = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"4.Credit Transaction Question\">4.Credit Transaction Question</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"total amount\">4.1 What is total amount spending captured in this dataset?</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount spend captured is $195165813.35\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total amount spend captured is ${cleaned_credit_df['Cleaned_Amount'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"4.2 How much was spend at WW GRAINGER?\">4.2 How much was spend at WW GRAINGER?</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$5360772.380000001 was spend at WW GRAINGER\n"
     ]
    }
   ],
   "source": [
    "print(f\"${cleaned_credit_df[cleaned_credit_df['Vendor'] == 'WW GRAINGER']['Cleaned_Amount'].sum()} was spend at WW GRAINGER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"4.3 How much was spend at WM SUPERCENTER?\">4.3 How much was spend at WM SUPERCENTER?</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total $31777.83 was spend at WM SUPERCENTER\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total ${cleaned_credit_df[cleaned_credit_df['Vendor'] == 'WM SUPERCENTER']['Cleaned_Amount'].sum()} was spend at WM SUPERCENTER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"4.4 How much was spend at GROCERY STORES?\">4.4 How much was spend at GROCERY STORES?</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I check the columns, the target column name should be <code>['Merchant Category Code (MCC)']</code> and target variable/category should be <code>\"GROCERY STORES,AND SUPERMARKETS\"</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total $1322011.54 was spend at GROCERY STORES,AND SUPERMARKETS\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total ${cleaned_credit_df[cleaned_credit_df['Merchant Category Code (MCC)'] == 'GROCERY STORES,AND SUPERMARKETS']['Cleaned_Amount'].sum()} was spend at GROCERY STORES,AND SUPERMARKETS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"5.Energy Pandas Question\">5.Energy Pandas Question</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All output and analysis will be present by main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5.1 Read ’Energy.xlsx’ and ’EnergyRating.xlsx’ ******************************\n",
      "Energy.xlsx is a (844, 380) BalanceSheet\n",
      "EnergyRating.xlsx is a (2522, 7) Ratings\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.2 Drop the column if more than 90% value in this colnmn is 0’ ******************************\n",
      "Total 122 columns has been dropped\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.3 Replace all None or NaN with average value of each column’ ******************************\n",
      "Before fill nan, \n",
      "we have 19 columns don't contain np.nan value,\n",
      "we have 239 columns contain np.nan value\n",
      "After fill nan, \n",
      "we have 258 columns don't have np.nan value\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.2 Drop the column if more than 90% value in this colnmn is 0’ ******************************\n",
      "Total 1 columns has been dropped\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.3 Replace all None or NaN with average value of each column’ ******************************\n",
      "Before fill nan, \n",
      "we have 4 columns don't contain np.nan value,\n",
      "we have 2 columns contain np.nan value\n",
      "After fill nan, \n",
      "we have 4 columns don't have np.nan value\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.4 Normalize the table ******************************\n",
      "There are 241 columns are numerical by MinMax method.\n",
      "****************************** End normalize() with 0.1227 second ****************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.5 Simulate describe() function ******************************\n",
      "       Current Assets - Other - Total  Current Assets - Total  \\\n",
      "count                      844.000000              844.000000   \n",
      "mean                      1037.255108             9735.614198   \n",
      "std                       1578.836159            13568.222671   \n",
      "min                          2.671000              144.786000   \n",
      "25%                        181.500000             1499.018250   \n",
      "50%                        448.677000             4744.000000   \n",
      "75%                       1037.255108            11617.250000   \n",
      "max                       9476.000000            76160.000000   \n",
      "\n",
      "       Other Long-term Assets  \n",
      "count              844.000000  \n",
      "mean              1486.818614  \n",
      "std               2441.795091  \n",
      "min                 13.072000  \n",
      "25%                187.456000  \n",
      "50%                827.000000  \n",
      "75%               1492.000000  \n",
      "max              40233.000000  \n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.6 Calculate the correlation matrix ******************************\n",
      "<bound method DataFrame.corr of      Current Assets - Other - Total  Current Assets - Total  \\\n",
      "0                            1502.0                  8780.0   \n",
      "1                            1434.0                  8296.0   \n",
      "2                             865.0                  8839.0   \n",
      "3                            1002.0                  8780.0   \n",
      "4                             759.0                  9436.0   \n",
      "..                              ...                     ...   \n",
      "839                           183.0                  9471.0   \n",
      "840                           204.0                  8097.0   \n",
      "841                           142.0                 10304.0   \n",
      "842                           176.0                  9545.0   \n",
      "843                           236.0                 10401.0   \n",
      "\n",
      "     Other Long-term Assets  \n",
      "0                    2568.0  \n",
      "1                    2587.0  \n",
      "2                    2742.0  \n",
      "3                    2638.0  \n",
      "4                    2602.0  \n",
      "..                      ...  \n",
      "839                   119.0  \n",
      "840                   886.0  \n",
      "841                   875.0  \n",
      "842                   848.0  \n",
      "843                   107.0  \n",
      "\n",
      "[844 rows x 3 columns]>\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.7 Extract Company Postfix ******************************\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.8 Merge on ['Data Date', 'Global Company Key'] with two DataFrame ******************************\n",
      "New Datase have (822, 263) size\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.9 Transform Alpha Format to Numerical Format ******************************\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n",
      "****************************** 5.10 Distribute Frequence ******************************\n",
      "**************************************** END **************************************** \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    (cleaned_credit_df, balance_sheet_df, rating_df, cleaned_balance_df, cleaned_rating_df,\n",
    "     norm_df, Matched)   = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"Test Code\">6. Test Code</a>\n",
    "<a href=\"#2.Table of Contents\">Click this Link back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"03_data/res_purchase_2014.csv\", low_memory=False)\n",
    "\n",
    "# amount_series = df['Amount']\n",
    "\n",
    "# def clean_data(x):\n",
    "#     if x[0] == '(' and x[-1] == ')':\n",
    "#         x_new = re.findall('\\d*\\.?\\d+', x)\n",
    "#         return -float(x_new[0])\n",
    "#     else:\n",
    "#         x_other = re.findall('\\d*\\.?\\d+', x)\n",
    "#         return float(x_other[0])\n",
    "\n",
    "# df['Cleaned_Amount'] = df['Amount'].apply(clean_data)\n",
    "\n",
    "# df['Cleaned_Amount'].loc[7:10]\n",
    "\n",
    "# df['Cleaned_Amount'].sum()\n",
    "\n",
    "\n",
    "\n",
    "# Matched['CO']\n",
    "\n",
    "# Matched.groupby(['CO'])['CO'].count().plot(kind= 'bar')\n",
    "\n",
    "# cleaned_balance_df.shape\n",
    "\n",
    "# import copy\n",
    "\n",
    "# df_10 = cleaned_balance_df.copy()\n",
    "\n",
    "# def name_extract(x):\n",
    "#     \"\"\"\n",
    "#     Ues this function to extract the postfix from ['Company Name'] column\n",
    "#     \"\"\"\n",
    "#     return x.split(' ')[-1]\n",
    "\n",
    "# cleaned_balance_df['CO'] = cleaned_balance_df['Company Name'].map(lambda x: x.split(' ')[-1])\n",
    "# Matched = pd.merge(cleaned_balance_df, cleaned_rating_df, on=merge_list, how='inner')\n",
    "# Matched['Rate'] = Matched['S&P Domestic Long Term Issuer Credit Rating'].map(rating_numerical)\n",
    "\n",
    "# ax = Matched[Matched['CO'] == 'CO']['Rate'].plot.hist(bins=12, alpha=0.5)\n",
    "\n",
    "# test_15 = Matched[Matched['CO'] == 'CO'].groupby(['S&P Domestic Long Term Issuer Credit Rating'])['Rate'].count()\n",
    "\n",
    "# test_15.plot(kind = 'bar')\n",
    "\n",
    "# type(test_15)\n",
    "\n",
    "# ax = Matched[Matched['CO'] == 'CO'].groupby(['S&P Domestic Long Term Issuer Credit Rating']).count().plot.hist(bins=12, alpha=0.5)\n",
    "\n",
    "# Matched[Matched['CO'] == 'CO']['Rate']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cleaned_balance_df.name\n",
    "\n",
    "# dir(cleaned_balance_df)\n",
    "\n",
    "# cleaned_rating_df.shape\n",
    "\n",
    "# merge_list= ['Data Date','Global Company Key']\n",
    "\n",
    "# # cleaned_rating_df[['Data Date','Global Company Key']\n",
    "# cleaned_rating_df.columns\n",
    "\n",
    "# Matched = pd.merge(cleaned_balance_df, cleaned_rating_df, on=merge_list, how='inner')\n",
    "\n",
    "# def rating_numerical(x):\n",
    "#     if x == 'AAA':\n",
    "#         return 0\n",
    "#     elif x == 'AA+':\n",
    "#         return 1\n",
    "#     elif x == 'AA':\n",
    "#         return 2\n",
    "#     elif x == 'AA-':\n",
    "#         return 3\n",
    "#     elif x == 'A+':\n",
    "#         return 4\n",
    "#     elif x == 'A':\n",
    "#         return 5\n",
    "#     elif x == 'A-':\n",
    "#         return 6\n",
    "#     elif x == 'BBB+':\n",
    "#         return 7\n",
    "#     elif x == 'BBB':\n",
    "#         return 8\n",
    "#     elif x == 'BBB-':\n",
    "#         return 9\n",
    "#     elif x == 'BB+':\n",
    "#         return 10\n",
    "#     elif x =='BB':\n",
    "#         return 11\n",
    "#     else:\n",
    "#         return 12\n",
    "\n",
    "# rate_1 = Matched['S&P Domestic Long Term Issuer Credit Rating'].map(lambda x:str(x).lower())\n",
    "\n",
    "# Matched['Rate'] = Matched['S&P Domestic Long Term Issuer Credit Rating'].map(rating_numerical)\n",
    "\n",
    "# Matched.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_11.columns\n",
    "\n",
    "# cleaned_balance_df[merge_list]\n",
    "\n",
    "\n",
    "\n",
    "# cleaned_balance_df.groupby(['Company Name']).count()\n",
    "\n",
    "\n",
    "\n",
    "# # original_col = list(balance_sheet_df.columns)\n",
    "\n",
    "# # col_list = list(cleaned_balance_df.columns)\n",
    "\n",
    "# # print(balance_sheet_df[\"Assets Netting & Other Adjustments\"].quantile(q=0.3))\n",
    "# # print(balance_sheet_df[\"Assets Netting & Other Adjustments\"].quantile(q=0.5))\n",
    "# # print(balance_sheet_df[\"Assets Netting & Other Adjustments\"].quantile(q=0.7))\n",
    "# # print(balance_sheet_df[\"Assets Netting & Other Adjustments\"].quantile(q=0.9))\n",
    "\n",
    "# # type(col_list)\n",
    "\n",
    "\n",
    "# # # according to double-check, \"Assets Netting & Other Adjustments\" this column has been dropped in first step because zero\n",
    "# # test_list = [\"Current Assets - Other - Total\",\n",
    "# #              \"Current Assets - Total\",\n",
    "# #              \"Other Long-term Assets\"]\n",
    "\n",
    "# # def statistic_info(x):\n",
    "# #     \"\"\"\n",
    "# #     \"\"\"\n",
    "# #     ser = pd.Series([x.count(), x.mean(), x.std(), x.min(), x.quantile(0.25), x.quantile(0.5), x.quantile(0.75), x.max()],\n",
    "# #                      index=['count','mean','std','min', '25%', '50%', '75%', 'max'] )\n",
    "# #     return ser\n",
    "\n",
    "# # df_17 = cleaned_balance_df[test_list]\n",
    "\n",
    "# # pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "# # print(df_17.apply(statistic_info))\n",
    "\n",
    "# # df_17.corr()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # type(test_list)\n",
    "\n",
    "# # col_list\n",
    "\n",
    "# # sub = 'Assets'\n",
    "# # res = [i for i in original_col if sub in i] \n",
    "\n",
    "# # res\n",
    "\n",
    "# # sub = 'Current'\n",
    "# # for i in col_list:\n",
    "# #     if sub in i:\n",
    "# #         print(i)\n",
    "\n",
    "# # df_15 = cleaned_balance_df[\"Assets Netting & Other Adjustments\"]\n",
    "# # df_15\n",
    "\n",
    "# # cleaned_balance_df.shape\n",
    "\n",
    "# # def normalize(df):\n",
    "# #     \"\"\"\n",
    "# #     \"\"\"\n",
    "# #     df_norm = (df - df.min()) / (df.max() - df.min())\n",
    "# #     return df_norm\n",
    "    \n",
    "\n",
    "# # def test_fun(series):\n",
    "# #     print(series.__class__)\n",
    "\n",
    "# # len(remain_list)\n",
    "\n",
    "# # cleaned_balance_df.head(2)\n",
    "\n",
    "# # remain_list\n",
    "\n",
    "# # clean\n",
    "\n",
    "# # df_4 = cleaned_balance_df[remain_list[5:246]]\n",
    "# # print(type(df_4))\n",
    "# # df_4.head(5)\n",
    "# # df_norm2=df_4.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "# # df_norm2.head(3)\n",
    "# # print(df_norm2.shape)\n",
    "\n",
    "# # df_norm2=df_4.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "# # def normalize(series):\n",
    "# #     \"\"\"\n",
    "# #     Input will be column\n",
    "# #     \"\"\"\n",
    "    \n",
    "# #     return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# # df_5 = df_4.apply(normalize, axis = 0)\n",
    "\n",
    "# # df_6 = df_4.apply(lambda x:normalize(x), axis =0 )\n",
    "\n",
    "# # df_6\n",
    "\n",
    "# # remain_list[0:6]\n",
    "\n",
    "# # col_list = remain_list\n",
    "\n",
    "# # type(col_list)\n",
    "\n",
    "# # cleaned_balance_df.columns[0:7]\n",
    "\n",
    "# # deduct_list = ['Global Company Key',\n",
    "# #  'Data Date',\n",
    "# #  'Fiscal Year',\n",
    "# #  'Fiscal Quarter',\n",
    "# #  'Fiscal Year-end Month']\n",
    "# # deduct_list\n",
    "\n",
    "# # new_list = [item for item in remain_list if item not in deduct_list]\n",
    "# # # list[set(remain_list) - set(deduct_list)]\n",
    "\n",
    "# # len(new_list)\n",
    "\n",
    "# # df_5.head(4)\n",
    "\n",
    "# # df_5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # df_10 = pd.read_csv(\"03_data/res_purchase_2014.csv\")\n",
    "\n",
    "# # df_10.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # df_11 = df_10.iloc[:1000, 6]\n",
    "\n",
    "# # df_12\n",
    "\n",
    "# # df_4.loc[:,remain_list[5]] = df_4.loc[:,remain_list[5]].apply(normalize)\n",
    "\n",
    "# # df_4.head(5)\n",
    "\n",
    "\n",
    "\n",
    "# # corpus = corpus.apply(lambda x: remove_regex(x))\n",
    "\n",
    "# # col_dtype_series.__class__\n",
    "\n",
    "# # dir(col_dtype_series)\n",
    "\n",
    "# # col_dtype_series = cleaned_rating_df.dtypes\n",
    "# # col_dtype_series\n",
    "\n",
    "# # cleaned_rating_df\n",
    "\n",
    "# # col_dtype_series = cleaned_balance_df.dtypes\n",
    "# # col_dtype_series\n",
    "\n",
    "# # remain_list = []\n",
    "# # object_list = []\n",
    "# # for index, value in col_dtype_series.items():\n",
    "# #     if value == 'int64' or value == 'float64':\n",
    "# #         remain_list.append(index)\n",
    "# #     else:\n",
    "# #         print(index, value)\n",
    "# #         object_list.append(index)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import string\n",
    "# import re\n",
    "# # use this to moniter rate of progess\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# df = pd.read_csv(\"03_data/res_purchase_2014.csv\")\n",
    "\n",
    "# df[df['Vendor'] == 'WW GRAINGER']\n",
    "\n",
    "# df.iloc[15:78, 6]\n",
    "\n",
    "# amount[70:80]\n",
    "\n",
    "# # import pandas as pd\n",
    "# # import numpy as np\n",
    "# # import re\n",
    "# # import tqdm from tqdm\n",
    "\n",
    "# class EdaData(object):\n",
    "#     \"\"\"\n",
    "#     Try to use this class to answer first task\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def eda_data(self):\n",
    "#         \"\"\"\n",
    "\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         # read data\n",
    "#         self.df = pd.read_csv(\"03_data/res_purchase_2014.csv\")\n",
    "\n",
    "#         return self.df\n",
    "\n",
    "\n",
    "#     def clean_data(self):\n",
    "#         \"\"\"\n",
    "#         When we observe, we see ($29.99) to represent negative\n",
    "#         And there are some number have word, like zero, in this column\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         amount_series = self.df['Amount']\n",
    "#         # there are various data type and differnt context in ['amount'] column\n",
    "#         # we need clean data before analysis\n",
    "#         for idx, i in tqdm(enumerate(amount_series)):\n",
    "#             # first data are float type\n",
    "#             if type(i) == float:\n",
    "#                 #         print(i)\n",
    "#                 pass\n",
    "#             # we filter data from minority\n",
    "#             elif i[0] == '(' and i[-1] == ')':\n",
    "#                 #         print(i)\n",
    "#                 # this is specify for data($29,99)\n",
    "#                 i_new = i.replace('(', '')\n",
    "#                 i_new = i_new.replace(')', '')\n",
    "#                 # replace $ with - and transform to float\n",
    "#                 i_new = float(i_new.replace('$', '-'))\n",
    "#                 #         print(i_new, type(i_new))\n",
    "#                 # replace dataframe with new clean data\n",
    "#                 self.df.iloc[idx, 6] = i_new\n",
    "#             elif type(i) == str:\n",
    "#                 # use regex to extract float format numerical data\n",
    "#                 #         print(idx, type(i), i)\n",
    "#                 i_new = re.findall('\\d*\\.?\\d+', i)\n",
    "#                 self.df.iloc[idx, 6] = float(i_new[0])\n",
    "#             elif type(i) == int:\n",
    "#                 #         pass\n",
    "#                 # transform int to float\n",
    "#                 self.df.iloc[idx, 6] = float(i)\n",
    "#             #         print(i)\n",
    "#             # if former filter cannot process some data then print these unprocessed data\n",
    "#             else:\n",
    "#                 print(idx, type(i))\n",
    "\n",
    "#         # save to clean csv\n",
    "#         self.df.to_csv(\"03_data/cleaned_purchase_2014.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# df.to_csv(\"03_data/cleaned_purchase_2014.csv\")\n",
    "\n",
    "# for i in df['Amount']:\n",
    "#     if type(i) != float:\n",
    "#         print(i)\n",
    "\n",
    "# type(df['Amount'].any())==float \n",
    "\n",
    "# df.iloc[15:20, 6]\n",
    "\n",
    "\n",
    "\n",
    "# amount[15]\n",
    "\n",
    "# test_5 = amount[15]\n",
    "# print(test_5)\n",
    "# test_6 = re.findall('\\d*\\.?\\d+', test_5)\n",
    "# print(type(float(test_6[0])))\n",
    "# # print(type(test_6.string()))\n",
    "# # test_7 = float(test_6)\n",
    "# # print(type(test_7))\n",
    "# # # for i in test_6:\n",
    "# # #     test_7 = float(i)\n",
    "\n",
    "# type(test_6)\n",
    "\n",
    "# dir(test_6)\n",
    "\n",
    "# test_3 = amount[9]\n",
    "# test_3\n",
    "\n",
    "# type(test_3)\n",
    "\n",
    "# test_3.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# string.punctuation\n",
    "\n",
    "# test_4 = test_3.replace('(', '')\n",
    "\n",
    "# test_4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clean_df = pd.read_csv('03_data/cleaned_purchase_2014.csv')\n",
    "\n",
    "# clean_df['Amount'].sum()\n",
    "\n",
    "\n",
    "\n",
    "# balance_sheet_df = pd.read_excel('03_data/Energy.xlsx')\n",
    "# rating_df = pd.read_excel('03_data/EnergyRating.xlsx')\n",
    "\n",
    "# balance_sheet_df.shape\n",
    "\n",
    "# cleaned_balance_df = balance_sheet_df.drop(columns=drop_list)\n",
    "\n",
    "# cleaned_balance_df.shape\n",
    "\n",
    "# cleaned_balance_df.head(3)\n",
    "\n",
    "# cleaned_balance_df.shape\n",
    "\n",
    "# cleaned_balance_df.mean(axis = 0)\n",
    "\n",
    "# bool_3 = cleaned_balance_df.isnull().any()\n",
    "\n",
    "# from varname import varname\n",
    "# def test(df):\n",
    "#     df.head(5)\n",
    "#     x = varname(df)\n",
    "#     print(x)\n",
    "#     return x\n",
    "\n",
    "# !pip install varname\n",
    "\n",
    "\n",
    "# dir(cleaned_balance_df)\n",
    "\n",
    "# type(bool_3)\n",
    "\n",
    "# type(bool_3.value_counts())\n",
    "\n",
    "# bool_3.value_counts()\n",
    "\n",
    "# df_4 = cleaned_balance_df.fillna(cleaned_balance_df.mean(axis = 0))\n",
    "# df_4.head(5)\n",
    "\n",
    "# nan_list.value_counts()[0]\n",
    "\n",
    "# nan_list = df_4.isnull().any()\n",
    "# nan_list\n",
    "\n",
    "# for index,value in nan_list.items():\n",
    "#     if value:\n",
    "#         print(index, value)\n",
    "\n",
    "# column_list = [index for index,value in nan_list.items() if value]\n",
    "\n",
    "# column_list\n",
    "\n",
    "# cleaned_balance_df[column_list[0]]\n",
    "\n",
    "# type(balance_sheet_df[column_list[0]][0])\n",
    "\n",
    "# balance_sheet_df[column_list[0]].isna().any()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# quantile_1 = balance_sheet_df.quantile(q = 0.9, axis = 0)\n",
    "# quantile_1\n",
    "\n",
    "# type(quantile_1)\n",
    "\n",
    "# drop_list = []\n",
    "# suspicion_list = []\n",
    "# remain_list = []\n",
    "# for index,value in quantile_1.items():\n",
    "#     if value == 0 or value==np.nan:\n",
    "# #         print(index, value)\n",
    "#         drop_list.append(index)\n",
    "#     elif balance_sheet_df[index].isna().all():\n",
    "#         print(\"*\"*20, index, value, \"*\"*20,end='\\n')\n",
    "#         drop_list.append(index)\n",
    "#     elif value < 10:\n",
    "# #         print(\"*\"*20, index, value, \"*\"*20,end='\\n')\n",
    "#         suspicion_list.append(index)\n",
    "#     else:\n",
    "#         remain_list.append(index)\n",
    "            \n",
    "\n",
    "# len(drop_list)\n",
    "\n",
    "# len(suspicion_list)\n",
    "\n",
    "# len(remain_list)\n",
    "\n",
    "\n",
    "\n",
    "# test_1_df = pd.read_excel('03_data/Energy.xlsx')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
